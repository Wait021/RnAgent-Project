#!/usr/bin/env python3
"""
RNAé¡¹ç›®ä¼˜åŒ–ç‰ˆæœ¬ - æ™ºèƒ½ç¼“å­˜ç®¡ç†ç³»ç»Ÿ
"""

import os
import pickle
import hashlib
import time
import psutil
import json
from pathlib import Path
from typing import Any, Dict, Optional, Tuple, List
from datetime import datetime, timedelta
from functools import wraps
from threading import Lock
import weakref
import gc

from config import get_config

class CacheEntry:
    """ç¼“å­˜æ¡ç›®"""
    
    def __init__(self, value: Any, ttl: int = 3600):
        self.value = value
        self.created_time = time.time()
        self.access_time = time.time()
        self.access_count = 1
        self.ttl = ttl
        self.size = self._calculate_size(value)
    
    def _calculate_size(self, obj: Any) -> int:
        """è®¡ç®—å¯¹è±¡å¤§å°ï¼ˆä¼°ç®—ï¼‰"""
        try:
            if hasattr(obj, '__sizeof__'):
                return obj.__sizeof__()
            else:
                return len(pickle.dumps(obj))
        except:
            return 1024  # é»˜è®¤1KB
    
    def is_expired(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¿‡æœŸ"""
        return time.time() - self.created_time > self.ttl
    
    def touch(self):
        """æ›´æ–°è®¿é—®æ—¶é—´"""
        self.access_time = time.time()
        self.access_count += 1

class InMemoryCache:
    """å†…å­˜ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, max_size: int = 512 * 1024 * 1024):  # 512MB
        self._cache: Dict[str, CacheEntry] = {}
        self._lock = Lock()
        self.max_size = max_size
        self.current_size = 0
        
    def _generate_key(self, func_name: str, args: tuple, kwargs: dict) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_data = {
            'func': func_name,
            'args': args,
            'kwargs': kwargs
        }
        key_str = json.dumps(key_data, sort_keys=True, default=str)
        return hashlib.md5(key_str.encode()).hexdigest()
    
    def get(self, key: str) -> Optional[Any]:
        """è·å–ç¼“å­˜å€¼"""
        with self._lock:
            if key in self._cache:
                entry = self._cache[key]
                if entry.is_expired():
                    del self._cache[key]
                    self.current_size -= entry.size
                    return None
                else:
                    entry.touch()
                    return entry.value
        return None
    
    def set(self, key: str, value: Any, ttl: int = 3600):
        """è®¾ç½®ç¼“å­˜å€¼"""
        with self._lock:
            entry = CacheEntry(value, ttl)
            
            # æ£€æŸ¥å†…å­˜ä½¿ç”¨ç‡
            if self._should_evict(entry.size):
                self._evict_entries(entry.size)
            
            # å¦‚æœé”®å·²å­˜åœ¨ï¼Œæ›´æ–°å¤§å°
            if key in self._cache:
                self.current_size -= self._cache[key].size
            
            self._cache[key] = entry
            self.current_size += entry.size
    
    def _should_evict(self, new_size: int) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦æ¸…ç†ç¼“å­˜"""
        return (self.current_size + new_size) > self.max_size
    
    def _evict_entries(self, required_size: int):
        """æ¸…ç†ç¼“å­˜æ¡ç›®ï¼ˆLRUç­–ç•¥ï¼‰"""
        # æŒ‰è®¿é—®æ—¶é—´æ’åºï¼Œä¼˜å…ˆæ¸…ç†æœ€ä¹…æœªè®¿é—®çš„
        sorted_items = sorted(
            self._cache.items(),
            key=lambda x: x[1].access_time
        )
        
        freed_size = 0
        for key, entry in sorted_items:
            if freed_size >= required_size:
                break
            
            del self._cache[key]
            freed_size += entry.size
            self.current_size -= entry.size
    
    def clear(self):
        """æ¸…ç©ºç¼“å­˜"""
        with self._lock:
            self._cache.clear()
            self.current_size = 0
    
    def stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        with self._lock:
            total_entries = len(self._cache)
            total_accesses = sum(entry.access_count for entry in self._cache.values())
            
            return {
                "total_entries": total_entries,
                "current_size_mb": round(self.current_size / (1024 * 1024), 2),
                "max_size_mb": round(self.max_size / (1024 * 1024), 2),
                "memory_usage_percent": round((self.current_size / self.max_size) * 100, 2),
                "total_accesses": total_accesses,
                "avg_accesses_per_entry": round(total_accesses / max(total_entries, 1), 2)
            }

class DiskCache:
    """ç£ç›˜ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, cache_dir: str):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self._lock = Lock()
    
    def _get_file_path(self, key: str) -> Path:
        """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        return self.cache_dir / f"{key}.cache"
    
    def _get_meta_path(self, key: str) -> Path:
        """è·å–å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„"""
        return self.cache_dir / f"{key}.meta"
    
    def get(self, key: str) -> Optional[Any]:
        """ä»ç£ç›˜è·å–ç¼“å­˜"""
        file_path = self._get_file_path(key)
        meta_path = self._get_meta_path(key)
        
        if not file_path.exists() or not meta_path.exists():
            return None
        
        try:
            # æ£€æŸ¥å…ƒæ•°æ®
            with open(meta_path, 'r') as f:
                meta = json.load(f)
            
            # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
            if time.time() > meta['expires_at']:
                self._remove_cache_files(key)
                return None
            
            # è¯»å–ç¼“å­˜æ•°æ®
            with open(file_path, 'rb') as f:
                value = pickle.load(f)
            
            # æ›´æ–°è®¿é—®æ—¶é—´
            meta['access_time'] = time.time()
            meta['access_count'] += 1
            with open(meta_path, 'w') as f:
                json.dump(meta, f)
            
            return value
            
        except Exception as e:
            print(f"è¯»å–ç£ç›˜ç¼“å­˜å¤±è´¥: {e}")
            self._remove_cache_files(key)
            return None
    
    def set(self, key: str, value: Any, ttl: int = 3600):
        """ä¿å­˜åˆ°ç£ç›˜ç¼“å­˜"""
        file_path = self._get_file_path(key)
        meta_path = self._get_meta_path(key)
        
        try:
            with self._lock:
                # ä¿å­˜æ•°æ®
                with open(file_path, 'wb') as f:
                    pickle.dump(value, f)
                
                # ä¿å­˜å…ƒæ•°æ®
                meta = {
                    'created_time': time.time(),
                    'access_time': time.time(),
                    'access_count': 1,
                    'expires_at': time.time() + ttl,
                    'ttl': ttl
                }
                with open(meta_path, 'w') as f:
                    json.dump(meta, f)
                    
        except Exception as e:
            print(f"ä¿å­˜ç£ç›˜ç¼“å­˜å¤±è´¥: {e}")
            self._remove_cache_files(key)
    
    def _remove_cache_files(self, key: str):
        """åˆ é™¤ç¼“å­˜æ–‡ä»¶"""
        file_path = self._get_file_path(key)
        meta_path = self._get_meta_path(key)
        
        try:
            if file_path.exists():
                file_path.unlink()
            if meta_path.exists():
                meta_path.unlink()
        except Exception as e:
            print(f"åˆ é™¤ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}")
    
    def clear(self):
        """æ¸…ç©ºç£ç›˜ç¼“å­˜"""
        try:
            for file_path in self.cache_dir.glob("*.cache"):
                file_path.unlink()
            for file_path in self.cache_dir.glob("*.meta"):
                file_path.unlink()
        except Exception as e:
            print(f"æ¸…ç©ºç£ç›˜ç¼“å­˜å¤±è´¥: {e}")
    
    def cleanup_expired(self):
        """æ¸…ç†è¿‡æœŸçš„ç¼“å­˜æ–‡ä»¶"""
        current_time = time.time()
        
        for meta_path in self.cache_dir.glob("*.meta"):
            try:
                with open(meta_path, 'r') as f:
                    meta = json.load(f)
                
                if current_time > meta['expires_at']:
                    key = meta_path.stem
                    self._remove_cache_files(key)
                    
            except Exception as e:
                print(f"æ¸…ç†è¿‡æœŸç¼“å­˜å¤±è´¥: {e}")
                # åˆ é™¤æŸåçš„æ–‡ä»¶
                try:
                    meta_path.unlink()
                except:
                    pass

class CacheManager:
    """ç»Ÿä¸€ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self):
        self.config = get_config()
        self.memory_cache = InMemoryCache()
        self.disk_cache = DiskCache(self.config.get_cache_path())
        self._cleanup_timer = None
        self._start_cleanup_timer()
    
    def cache_result(self, ttl: int = 3600, use_disk: bool = False):
        """ç¼“å­˜è£…é¥°å™¨"""
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                # ç”Ÿæˆç¼“å­˜é”®
                key = self.memory_cache._generate_key(func.__name__, args, kwargs)
                
                # å…ˆå°è¯•å†…å­˜ç¼“å­˜
                result = self.memory_cache.get(key)
                if result is not None:
                    return result
                
                # å†å°è¯•ç£ç›˜ç¼“å­˜
                if use_disk and self.config.cache.enable_data_cache:
                    result = self.disk_cache.get(key)
                    if result is not None:
                        # å°†ç»“æœæ”¾å›å†…å­˜ç¼“å­˜
                        self.memory_cache.set(key, result, ttl)
                        return result
                
                # ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œå‡½æ•°
                result = func(*args, **kwargs)
                
                # ä¿å­˜åˆ°ç¼“å­˜
                self.memory_cache.set(key, result, ttl)
                if use_disk and self.config.cache.enable_data_cache:
                    self.disk_cache.set(key, result, ttl)
                
                return result
            return wrapper
        return decorator
    
    def _start_cleanup_timer(self):
        """å¯åŠ¨å®šæœŸæ¸…ç†ä»»åŠ¡"""
        import threading
        
        def cleanup_task():
            while True:
                time.sleep(self.config.cache.cache_cleanup_interval)
                self.cleanup()
        
        cleanup_thread = threading.Thread(target=cleanup_task, daemon=True)
        cleanup_thread.start()
    
    def cleanup(self):
        """æ¸…ç†è¿‡æœŸç¼“å­˜"""
        try:
            # æ¸…ç†ç£ç›˜ç¼“å­˜
            self.disk_cache.cleanup_expired()
            
            # æ£€æŸ¥å†…å­˜ä½¿ç”¨ç‡
            memory_percent = psutil.virtual_memory().percent
            if memory_percent > self.config.performance.memory_threshold * 100:
                # å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œæ¸…ç†éƒ¨åˆ†å†…å­˜ç¼“å­˜
                self.memory_cache._evict_entries(self.memory_cache.current_size // 4)
                gc.collect()  # å¼ºåˆ¶åƒåœ¾å›æ”¶
                
        except Exception as e:
            print(f"ç¼“å­˜æ¸…ç†å¤±è´¥: {e}")
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        memory_stats = self.memory_cache.stats()
        
        # ç£ç›˜ç¼“å­˜ç»Ÿè®¡
        disk_files = list(self.disk_cache.cache_dir.glob("*.cache"))
        disk_size = sum(f.stat().st_size for f in disk_files)
        
        system_memory = psutil.virtual_memory()
        
        return {
            "memory_cache": memory_stats,
            "disk_cache": {
                "total_files": len(disk_files),
                "total_size_mb": round(disk_size / (1024 * 1024), 2)
            },
            "system_memory": {
                "total_gb": round(system_memory.total / (1024**3), 2),
                "available_gb": round(system_memory.available / (1024**3), 2),
                "used_percent": system_memory.percent
            }
        }
    
    def clear_all(self):
        """æ¸…ç©ºæ‰€æœ‰ç¼“å­˜"""
        self.memory_cache.clear()
        self.disk_cache.clear()

# å…¨å±€ç¼“å­˜ç®¡ç†å™¨å®ä¾‹
_cache_manager = None

def get_cache_manager() -> CacheManager:
    """è·å–å…¨å±€ç¼“å­˜ç®¡ç†å™¨å®ä¾‹"""
    global _cache_manager
    if _cache_manager is None:
        _cache_manager = CacheManager()
    return _cache_manager

# ä¾¿æ·è£…é¥°å™¨
def cache_result(ttl: int = 3600, use_disk: bool = False):
    """ç¼“å­˜ç»“æœè£…é¥°å™¨"""
    return get_cache_manager().cache_result(ttl, use_disk)

if __name__ == "__main__":
    # ç¼“å­˜ç³»ç»Ÿæµ‹è¯•
    cache_mgr = get_cache_manager()
    
    @cache_result(ttl=60, use_disk=True)
    def expensive_calculation(n: int) -> int:
        """æ¨¡æ‹Ÿè€—æ—¶è®¡ç®—"""
        time.sleep(2)
        return sum(range(n))
    
    print("ğŸ§ª æµ‹è¯•ç¼“å­˜ç³»ç»Ÿ...")
    
    start_time = time.time()
    result1 = expensive_calculation(1000)
    first_time = time.time() - start_time
    print(f"é¦–æ¬¡è°ƒç”¨: {result1}, è€—æ—¶: {first_time:.2f}s")
    
    start_time = time.time()
    result2 = expensive_calculation(1000)
    second_time = time.time() - start_time
    print(f"ç¼“å­˜è°ƒç”¨: {result2}, è€—æ—¶: {second_time:.2f}s")
    
    print(f"æ€§èƒ½æå‡: {first_time/second_time:.2f}x")
    print(f"ç¼“å­˜ç»Ÿè®¡: {cache_mgr.get_stats()}") 