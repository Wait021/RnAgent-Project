#!/usr/bin/env python3
"""
RnAgent å‰ç«¯åº”ç”¨ - é‡æ„ç¾åŒ–ç‰ˆæœ¬
æ¨¡å—åŒ–è®¾è®¡ï¼Œä¿æŒé€»è¾‘ä¸å˜ï¼Œæå‡è§†è§‰ä½“éªŒ
"""

import streamlit as st
import os
import sys
import asyncio
import json
import requests
import logging
import time
from pathlib import Path
from typing import List, Dict, Any, Optional, Union
from datetime import datetime
from dotenv import load_dotenv
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage, BaseMessage, SystemMessage
from langchain_openai import ChatOpenAI
from pydantic import SecretStr
from mcp.client.session import ClientSession
from mcp.client.sse import sse_client
from uuid import uuid4

# è®¾ç½®è¯¦ç»†çš„æ—¥å¿—æ ¼å¼
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(name)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('rna_streamlit_app.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# MCPæœåŠ¡å™¨URL
MCP_SERVER_URL = "http://localhost:8000/sse"
# Agent Core HTTP API
AGENT_CORE_CHAT_URL = "http://localhost:8002/chat"
AGENT_CORE_CONVERSATIONS_URL = "http://localhost:8002/conversations"

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="RnAgent - å•ç»†èƒRNAåˆ†ææ™ºèƒ½ä½“",
    page_icon="ğŸ§¬",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        "About": "### ğŸ§¬ RnAgent v2.1\nåŸºäºMCPæ¶æ„çš„å•ç»†èƒRNAåˆ†ææ™ºèƒ½ä½“\n\nâœ¨ æ”¯æŒå¯¹è¯è®°å¿† | è‡ªç„¶è¯­è¨€äº¤äº’ | å¯è§†åŒ–åˆ†æ",
        "Get Help": "https://github.com/your-repo/RnAgent",
        "Report a Bug": "https://github.com/your-repo/RnAgent/issues"
    }
)

# ========= UI ç»„ä»¶å‡½æ•° =========

def inject_global_style():
    """æ³¨å…¥å…¨å±€æ ·å¼å’Œä¸»é¢˜"""
    st.markdown(
        """
        <style>
            /* CSSå˜é‡å®šä¹‰ */
            :root {
                --primary-color: #667eea;
                --secondary-color: #764ba2;
                --success-color: #4caf50;
                --error-color: #f44336;
                --warning-color: #ff9800;
                --info-color: #2196f3;
                --text-primary: #1a1a1a;
                --text-secondary: #666;
                --bg-primary: #ffffff;
                --bg-secondary: #f8fafc;
                --border-radius: 12px;
                --shadow-sm: 0 2px 8px rgba(0,0,0,0.1);
                --shadow-md: 0 4px 16px rgba(0,0,0,0.15);
                --transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
            }

            /* æ·±è‰²æ¨¡å¼é€‚é… */
            @media (prefers-color-scheme: dark) {
                :root {
                    --text-primary: #ffffff;
                    --text-secondary: #b0b0b0;
                    --bg-primary: #1a1a1a;
                    --bg-secondary: #2d2d2d;
                }
                
                /* æ·±è‰²æ¨¡å¼ä¸‹çš„ä¾§è¾¹æ  */
                .stSidebar {
                    background: linear-gradient(180deg, #1e1e2d 0%, #2d2d3a 100%) !important;
                }
                
                /* æ·±è‰²æ¨¡å¼ä¸‹çš„æ¶ˆæ¯æ ·å¼ */
                .user-message {
                    background: linear-gradient(135deg, #1e3a8a 0%, #1e40af 100%);
                    color: #bfdbfe;
                }
                
                .assistant-message {
                    background: linear-gradient(135deg, #166534 0%, #15803d 100%);
                    color: #bbf7d0;
                }
                
                .assistant-message-with-tools {
                    background: linear-gradient(135deg, #6b21a8 0%, #7c3aed 100%);
                    color: #e9d5ff;
                }
                
                .tool-message {
                    background: linear-gradient(135deg, #b45309 0%, #d97706 100%);
                    color: #fed7aa;
                }
                
                /* æ·±è‰²æ¨¡å¼ä¸‹çš„æ ‡ç­¾æ ·å¼ */
                .user-label { color: #93c5fd; }
                .assistant-label { color: #86efac; }
                .assistant-label-with-tools { color: #d8b4fe; }
                .tool-label { color: #fdba74; }
                
                /* æ·±è‰²æ¨¡å¼ä¸‹çš„å·¥å…·è°ƒç”¨çŠ¶æ€ */
                .tool-pending {
                    background: linear-gradient(135deg, #4c1d95 0%, #5b21b6 100%);
                }
                
                .tool-executed {
                    background: linear-gradient(135deg, #14532d 0%, #166534 100%);
                }
            }

            /* ä¸»æ ‡é¢˜æ ·å¼ */
            .main-title {
                text-align: center;
                background: linear-gradient(135deg, var(--primary-color) 0%, var(--secondary-color) 100%);
                -webkit-background-clip: text;
                -webkit-text-fill-color: transparent;
                background-clip: text;
                font-size: 2.5rem;
                font-weight: 800;
                margin: 2rem 0;
                animation: title-glow 3s ease-in-out infinite alternate;
            }

            @keyframes title-glow {
                from { filter: drop-shadow(0 0 20px rgba(102, 126, 234, 0.5)); }
                to { filter: drop-shadow(0 0 30px rgba(118, 75, 162, 0.7)); }
            }

        /* çŠ¶æ€æŒ‡ç¤ºå™¨ */
            .status-indicator {
                display: inline-block;
                width: 10px;
                height: 10px;
                border-radius: 50%;
                margin-right: 6px;
                animation: pulse 2s infinite;
            }
            .status-online { background: var(--success-color); }
            .status-offline { background: var(--error-color); }

            @keyframes pulse {
                0%, 100% { opacity: 1; }
                50% { opacity: 0.5; }
            }

            /* èŠå¤©æ¶ˆæ¯æ ·å¼ */
            .chat-message {
                padding: 16px 20px;
                border-radius: var(--border-radius);
                margin-bottom: 16px;
                border-left: 4px solid;
                box-shadow: var(--shadow-sm);
                transition: var(--transition);
                position: relative;
                overflow: hidden;
        }
        
        .chat-message:hover {
            transform: translateY(-2px);
                box-shadow: var(--shadow-md);
            }

            .chat-message::before {
                content: '';
                position: absolute;
                top: 0;
                left: 0;
                right: 0;
                height: 2px;
                background: linear-gradient(90deg, transparent, rgba(255,255,255,0.3), transparent);
                animation: shimmer 2s infinite;
            }

            @keyframes shimmer {
                0% { transform: translateX(-100%); }
                100% { transform: translateX(100%); }
            }

            /* æ¶ˆæ¯ç±»å‹æ ·å¼ */
            .user-message {
            background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
            border-left-color: #1976d2;
            color: #0d47a1;
        }

            .assistant-message {
            background: linear-gradient(135deg, #e8f5e8 0%, #c8e6c9 100%);
            border-left-color: #388e3c;
            color: #1b5e20;
        }

            .assistant-message-with-tools {
            background: linear-gradient(135deg, #f3e5f5 0%, #e1bee7 100%);
            border-left-color: #7b1fa2;
            color: #4a148c;
        }

            .assistant-message-with-tools::after {
            content: "ğŸ”§";
            position: absolute;
                top: 12px;
                right: 16px;
                font-size: 18px;
            opacity: 0.7;
        }

            .tool-message {
            background: linear-gradient(135deg, #fff3e0 0%, #ffcc80 100%);
            border-left-color: #f57c00;
            color: #e65100;
        }

            /* å·¥å…·è°ƒç”¨çŠ¶æ€ */
            .tool-pending {
            background: linear-gradient(135deg, #f3e5f5 0%, #e1bee7 100%);
            border: 2px dashed #9c27b0;
                padding: 20px;
                border-radius: var(--border-radius);
                margin: 16px 0;
            animation: pulse-border 2s infinite;
        }

        @keyframes pulse-border {
            0% { border-color: #9c27b0; }
            50% { border-color: #e91e63; }
            100% { border-color: #9c27b0; }
        }

            .tool-executed {
            background: linear-gradient(135deg, #e8f5e8 0%, #c8e6c9 100%);
                border: 2px solid var(--success-color);
                padding: 20px;
                border-radius: var(--border-radius);
                margin: 16px 0;
            }

            /* æ ‡ç­¾æ ·å¼ */
            .message-label {
                font-weight: 700;
                text-shadow: 1px 1px 2px rgba(0,0,0,0.1);
                margin-bottom: 8px;
                display: block;
            }

            .user-label { color: #1976d2; }
            .assistant-label { color: #388e3c; }
            .assistant-label-with-tools { color: #7b1fa2; }
            .tool-label { color: #f57c00; }

            /* æŒ‰é’®å¢å¼º */
            .stButton > button {
            border-radius: 8px;
            font-weight: 600;
                transition: var(--transition);
                border: none;
                box-shadow: var(--shadow-sm);
        }

            .stButton > button:hover {
            transform: translateY(-2px);
                box-shadow: var(--shadow-md);
            }

            /* å›¾ç‰‡å¢å¼º */
            .stImage > img {
                border-radius: 8px;
                box-shadow: var(--shadow-sm);
                transition: var(--transition);
            }

            .stImage:hover > img {
                transform: scale(1.02);
                box-shadow: var(--shadow-md);
            }

            /* ä¾§è¾¹æ æ ·å¼ - æµ…è‰²æ¨¡å¼ */
            .stSidebar {
                background: linear-gradient(180deg, #f8fafc 0%, #e2e8f0 100%);
            }
            
            /* æ·±è‰²æ¨¡å¼ä¸‹çš„ä¾§è¾¹æ æ ·å¼è¦†ç›– */
            @media (prefers-color-scheme: dark) {
                .stSidebar {
                    background: linear-gradient(180deg, #1e1e2d 0%, #2d2d3a 100%) !important;
                }
            }

            /* éšè—é»˜è®¤å…ƒç´  */
            .stDeployButton { display: none; }
            footer { visibility: hidden; }
            .stDecoration { display: none; }

            /* å“åº”å¼è®¾è®¡ */
            @media (max-width: 768px) {
                .main-title { font-size: 2rem; }
                .chat-message { padding: 12px 16px; }
            }
        </style>
        """,
        unsafe_allow_html=True
    )

def build_header():
    """æ„å»ºé¡µé¢å¤´éƒ¨"""
    st.markdown('<h1 class="main-title">ğŸ§¬ RnAgent - å•ç»†èƒRNAåˆ†ææ™ºèƒ½ä½“</h1>',
                unsafe_allow_html=True)

def build_sidebar():
    """æ„å»ºä¾§è¾¹æ """
    with st.sidebar:
        st.title("âš™ï¸ è®¾ç½®")

        # è·å–å¯ç”¨æ¨¡å‹
        available_models, openai_key, deepseek_key = get_available_models()

        # APIå¯†é’¥çŠ¶æ€
        st.subheader("ğŸ”‘ APIçŠ¶æ€")
        
        if openai_key:
            st.markdown('<span class="status-indicator status-online"></span>OpenAI API: å·²é…ç½®', 
                       unsafe_allow_html=True)
        else:
            st.markdown('<span class="status-indicator status-offline"></span>OpenAI API: æœªé…ç½®', 
                       unsafe_allow_html=True)

        if deepseek_key:
            st.markdown('<span class="status-indicator status-online"></span>DeepSeek API: å·²é…ç½®', 
                       unsafe_allow_html=True)
        else:
            st.markdown('<span class="status-indicator status-offline"></span>DeepSeek API: æœªé…ç½®', 
                       unsafe_allow_html=True)

        # æ¨¡å‹é€‰æ‹©
        st.subheader("ğŸ¤– æ¨¡å‹é€‰æ‹©")
        
        if available_models:
            model_keys = list(available_models.keys())
            default_index = 0
            if "OpenAI GPT-4o" in model_keys:
                default_index = model_keys.index("OpenAI GPT-4o")
            elif "OpenAI GPT-4 Turbo" in model_keys:
                default_index = model_keys.index("OpenAI GPT-4 Turbo")
            elif "DeepSeek Chat" in model_keys:
                default_index = model_keys.index("DeepSeek Chat")

            selected_model_name = st.selectbox(
                "é€‰æ‹©æ¨¡å‹",
                options=model_keys,
                index=default_index,
                help="è‡ªåŠ¨æ ¹æ®æ‚¨çš„APIå¯†é’¥ç­›é€‰å¯ç”¨æ¨¡å‹"
            )
            selected_model = available_models[selected_model_name]

            if selected_model.startswith("gpt"):
                st.info("ğŸ”¸ ä½¿ç”¨OpenAIæ¨¡å‹ï¼Œéœ€è¦ç¨³å®šçš„ç½‘ç»œè¿æ¥")
            elif selected_model.startswith("deepseek"):
                st.info("ğŸ”¸ ä½¿ç”¨DeepSeekæ¨¡å‹ï¼Œç»æµå®æƒ çš„é€‰æ‹©")
        else:
            st.error("âŒ æœªæ£€æµ‹åˆ°å¯ç”¨çš„APIå¯†é’¥")
            st.markdown("""
            **è¯·è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡ä¹‹ä¸€ï¼š**
            ```bash
            # OpenAI API
            export OPENAI_API_KEY="your_key"
            # DeepSeek API  
            export DEEPSEEK_API_KEY="your_key"
            ```
            """)
            selected_model = "gpt-4o"
            selected_model_name = "OpenAI GPT-4o (æœªé…ç½®)"

        # æœåŠ¡çŠ¶æ€
        st.subheader("ğŸ–¥ï¸ æœåŠ¡çŠ¶æ€")
        
        server_online = check_mcp_server_health()
        agent_online = check_agent_core_health()
        
        if server_online:
            st.markdown('<span class="status-indicator status-online"></span>MCPæœåŠ¡å™¨: åœ¨çº¿', 
                       unsafe_allow_html=True)
        else:
            st.markdown('<span class="status-indicator status-offline"></span>MCPæœåŠ¡å™¨: ç¦»çº¿', 
                       unsafe_allow_html=True)
            st.warning("âš ï¸ MCPæœåŠ¡å™¨ç¦»çº¿ï¼Œè¯·ç¡®ä¿åç«¯æœåŠ¡å™¨æ­£åœ¨è¿è¡Œ")

        if agent_online:
            st.markdown('<span class="status-indicator status-online"></span>Agent Core: åœ¨çº¿', 
                       unsafe_allow_html=True)
        else:
            st.markdown('<span class="status-indicator status-offline"></span>Agent Core: ç¦»çº¿', 
                       unsafe_allow_html=True)
            st.warning("âš ï¸ Agent Coreç¦»çº¿ï¼ŒèŠå¤©åŠŸèƒ½å°†ä¸å¯ç”¨")

        # æ˜¾ç¤ºè®¾ç½®
        st.subheader("ğŸ–¼ï¸ æ˜¾ç¤ºè®¾ç½®")
        image_width = st.slider(
            "å›¾è¡¨æ˜¾ç¤ºå®½åº¦ (åƒç´ )",
            min_value=400,
            max_value=1200,
            value=700,
            step=50,
            help="è°ƒæ•´ç”Ÿæˆå›¾è¡¨çš„æ˜¾ç¤ºå®½åº¦"
        )
        st.session_state.image_width = image_width

        # å¿«é€Ÿæ“ä½œ
        with st.expander("ğŸš€ å¿«é€Ÿæ“ä½œ", expanded=True):
            if not server_online:
                st.error("âŒ MCPæœåŠ¡å™¨ç¦»çº¿ï¼Œæ— æ³•ä½¿ç”¨å¿«é€Ÿæ“ä½œåŠŸèƒ½")
                st.info("ğŸ’¡ è¯·è¿è¡Œ `python run_rna_demo.py` å¯åŠ¨åç«¯æœåŠ¡å™¨")
            else:
                _render_quick_actions()

        # å¯¹è¯ç®¡ç†
        with st.expander("ğŸ’¬ å¯¹è¯ç®¡ç†", expanded=False):
            _render_conversation_management(agent_online)

        # æ•°æ®é›†ä¿¡æ¯
        with st.expander("ğŸ“ æ•°æ®é›†ä¿¡æ¯", expanded=False):
            _render_dataset_info()

        return selected_model, selected_model_name, server_online, agent_online

def _render_quick_actions():
    """æ¸²æŸ“å¿«é€Ÿæ“ä½œæŒ‰é’®"""
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ“Š åŠ è½½æ•°æ®", use_container_width=True):
            _execute_mcp_tool("load_pbmc3k_data", "æ­£åœ¨è·å–æ•°æ®åŠ è½½ä»£ç ...")
        if st.button("ğŸ” è´¨é‡æ§åˆ¶", use_container_width=True):
            _execute_mcp_tool("quality_control_analysis", "æ­£åœ¨è·å–è´¨é‡æ§åˆ¶ä»£ç ...")
        if st.button("âš™ï¸ é¢„å¤„ç†", use_container_width=True):
            _execute_mcp_tool("preprocessing_analysis", "æ­£åœ¨è·å–é¢„å¤„ç†ä»£ç ...")
        if st.button("ğŸ“ˆ é™ç»´åˆ†æ", use_container_width=True):
            _execute_mcp_tool("dimensionality_reduction_analysis", "æ­£åœ¨è·å–é™ç»´åˆ†æä»£ç ...")
    
    with col2:
        if st.button("ğŸ¯ èšç±»åˆ†æ", use_container_width=True):
            _execute_mcp_tool("clustering_analysis", "æ­£åœ¨è·å–èšç±»åˆ†æä»£ç ...")
        if st.button("ğŸ§¬ æ ‡è®°åŸºå› ", use_container_width=True):
            _execute_mcp_tool("marker_genes_analysis", "æ­£åœ¨è·å–æ ‡è®°åŸºå› åˆ†æä»£ç ...")
        if st.button("ğŸ“‹ ç”ŸæˆæŠ¥å‘Š", use_container_width=True):
            _execute_mcp_tool("generate_analysis_report", "æ­£åœ¨ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        if st.button("ğŸ”„ æ¸…ç©ºå¯¹è¯", use_container_width=True):
            _clear_conversation()

    st.divider()
    
    if st.button("ğŸš€ å®Œæ•´åˆ†ææµç¨‹", use_container_width=True, type="primary"):
        _execute_full_analysis()

def _execute_mcp_tool(tool_name: str, spinner_text: str):
    """æ‰§è¡ŒMCPå·¥å…·"""
    with st.spinner(spinner_text):
        result = call_mcp_tool_sync(tool_name, {})
        if isinstance(result, dict) and "content" in result:
            tool_message = build_tool_message(tool_name, result)
            st.session_state.messages.append(tool_message)
            st.rerun()

def _clear_conversation():
    """æ¸…ç©ºå¯¹è¯"""
    if st.session_state.conversation_id:
        if clear_conversation(st.session_state.conversation_id):
            st.success("âœ… å¯¹è¯å·²æ¸…ç©º")
        else:
            st.error("âŒ æ¸…ç©ºå¯¹è¯å¤±è´¥")
    
    st.session_state.messages = []
    st.session_state.conversation_id = None
    st.session_state.conversation_history = []
    st.session_state.pending_tool_calls = {}
    
    # æ¸…ç†å·¥å…·è°ƒç”¨çŠ¶æ€
    keys_to_remove = [key for key in st.session_state.keys() if key.startswith('executed_tool_')]
    for key in keys_to_remove:
        del st.session_state[key]
    
    st.rerun()

def _execute_full_analysis():
    """æ‰§è¡Œå®Œæ•´åˆ†ææµç¨‹"""
    analysis_steps = [
        ("load_pbmc3k_data", "ğŸ“Š åŠ è½½æ•°æ®"),
        ("quality_control_analysis", "ğŸ” è´¨é‡æ§åˆ¶"),
        ("preprocessing_analysis", "âš™ï¸ æ•°æ®é¢„å¤„ç†"),
        ("dimensionality_reduction_analysis", "ğŸ“ˆ é™ç»´åˆ†æ"),
        ("clustering_analysis", "ğŸ¯ èšç±»åˆ†æ"),
        ("marker_genes_analysis", "ğŸ§¬ æ ‡è®°åŸºå› åˆ†æ"),
        ("generate_analysis_report", "ğŸ“‹ ç”ŸæˆæŠ¥å‘Š")
    ]

    with st.spinner("æ­£åœ¨æ‰§è¡Œå®Œæ•´åˆ†ææµç¨‹..."):
        for tool_name, description in analysis_steps:
            st.info(f"æ­£åœ¨æ‰§è¡Œ: {description}")
            result = call_mcp_tool_sync(tool_name, {})
            if isinstance(result, dict) and "content" in result:
                tool_message = build_tool_message(tool_name, result)
                st.session_state.messages.append(tool_message)
            else:
                st.error(f"æ‰§è¡Œ {description} æ—¶å‡ºé”™")
                break
        st.success("âœ… å®Œæ•´åˆ†ææµç¨‹æ‰§è¡Œå®Œæ¯•ï¼")
        st.rerun()

def _render_conversation_management(agent_online: bool):
    """æ¸²æŸ“å¯¹è¯ç®¡ç†"""
    if st.session_state.conversation_id:
        st.info(f"ğŸ†” å½“å‰å¯¹è¯: {st.session_state.conversation_id[:8]}...")
        if st.button("ğŸ—‘ï¸ åˆ é™¤å½“å‰å¯¹è¯", use_container_width=True):
            if delete_conversation(st.session_state.conversation_id):
                st.success("âœ… å¯¹è¯å·²åˆ é™¤")
                st.session_state.conversation_id = None
                st.session_state.messages = []
                st.session_state.conversation_history = []
                st.session_state.pending_tool_calls = {}
                st.rerun()
            else:
                st.error("âŒ åˆ é™¤å¯¹è¯å¤±è´¥")
    else:
        st.info("ğŸ’­ å½“å‰æ²¡æœ‰æ´»è·ƒå¯¹è¯")
    
    if agent_online:
        st.subheader("ğŸ“‹ å†å²å¯¹è¯")
        conversations = get_conversations()
        if conversations:
            for conv in conversations[:5]:
                col1, col2 = st.columns([3, 1])
                with col1:
                    preview = conv.get("first_message", "æ— æ¶ˆæ¯")[:30]
                    if len(preview) == 30:
                        preview += "..."
                    st.text(f"ğŸ’¬ {preview}")
                    st.caption(f"æ¶ˆæ¯æ•°: {conv.get('message_count', 0)}")
                with col2:
                    if st.button("ğŸ“–", key=f"load_{conv['id']}", help="åŠ è½½æ­¤å¯¹è¯"):
                        st.session_state.conversation_id = conv['id']
                        st.session_state.messages = []
                        st.success(f"âœ… å·²åˆ‡æ¢åˆ°å¯¹è¯ {conv['id'][:8]}...")
                        st.rerun()
        else:
            st.info("ğŸ“­ æš‚æ— å†å²å¯¹è¯")

def _render_dataset_info():
    """æ¸²æŸ“æ•°æ®é›†ä¿¡æ¯"""
    current_file_path = Path(__file__).resolve()
    frontend_dir = current_file_path.parent
    rna_dir = frontend_dir.parent
    project_root = rna_dir.parent
    data_path = project_root / "PBMC3kRNA-seq" / "filtered_gene_bc_matrices" / "hg19"
    relative_path = os.path.relpath(str(data_path), str(project_root))
    
    st.info(f"""
    **PBMC3Kæ•°æ®é›†**
    - ç»†èƒç±»å‹: å¤–å‘¨è¡€å•æ ¸ç»†èƒ
    - å¹³å°: 10X Genomics
    - ç›¸å¯¹è·¯å¾„: `{relative_path}/`
    """)

def build_chat_area():
    """æ„å»ºèŠå¤©åŒºåŸŸ"""
    # æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯
    if not st.session_state.messages:
        _show_welcome_message()
    
    # æ˜¾ç¤ºå¯¹è¯å†å²
    for i, message in enumerate(st.session_state.messages):
        display_message(message, i)

def _show_welcome_message():
    """æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯"""
    current_models, current_openai, current_deepseek = get_available_models()
    
    welcome_msg = """
    ### ğŸ‘‹ æ¬¢è¿ä½¿ç”¨RnAgentï¼
    
    æˆ‘æ˜¯æ‚¨çš„å•ç»†èƒRNAåˆ†æåŠ©æ‰‹ï¼Œç°åœ¨æ”¯æŒ**å¯¹è¯è®°å¿†åŠŸèƒ½**ï¼æ‚¨å¯ä»¥ï¼š
    
    1. **ä½¿ç”¨ä¾§è¾¹æ å¿«é€Ÿæ“ä½œ**ï¼šç‚¹å‡»æŒ‰é’®æ‰§è¡Œé¢„å®šä¹‰çš„åˆ†ææ­¥éª¤
    2. **åœ¨ä¸‹æ–¹è¾“å…¥è‡ªç„¶è¯­è¨€é—®é¢˜**ï¼šæˆ‘ä¼šä¸ºæ‚¨ç”Ÿæˆç›¸åº”çš„åˆ†æä»£ç   
    3. **è¿è¡Œä»£ç å¹¶æŸ¥çœ‹ç»“æœ**ï¼šç”Ÿæˆçš„å›¾è¡¨ä¼šè‡ªåŠ¨æ˜¾ç¤º
    4. **ğŸ“š å¯¹è¯è®°å¿†**ï¼šæˆ‘ä¼šè®°ä½æ‚¨çš„å¯¹è¯å†å²ï¼Œæä¾›æ›´å¥½çš„ä¸Šä¸‹æ–‡ç†è§£
    
    **æ¨èå¼€å§‹æ–¹å¼**ï¼š
    - ç‚¹å‡»ä¾§è¾¹æ çš„"ğŸš€ å®Œæ•´åˆ†ææµç¨‹"æŒ‰é’®è¿›è¡Œç«¯åˆ°ç«¯åˆ†æ
    - æˆ–è€…é€æ­¥ç‚¹å‡»å„ä¸ªåˆ†ææ­¥éª¤
    - ä¹Ÿå¯ä»¥ç›´æ¥åœ¨ä¸‹æ–¹æé—®ï¼Œå¦‚"è¯·åŠ è½½PBMC3Kæ•°æ®å¹¶æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯"
    """

    if current_models:
        available_model_names = list(current_models.keys())
        welcome_msg += f"""
    **ğŸ¤– AIæ¨¡å‹çŠ¶æ€**ï¼š
    - âœ… å·²è‡ªåŠ¨æ£€æµ‹å¹¶é…ç½®å¯ç”¨æ¨¡å‹ï¼š{', '.join(available_model_names)}
    - ğŸ¯ å½“å‰é€‰æ‹©ï¼šå·²è‡ªåŠ¨ä¸ºæ‚¨é€‰æ‹©æœ€ä½³æ¨¡å‹
    - ğŸ’­ å¯¹è¯è®°å¿†ï¼šå·²å¯ç”¨ï¼Œæˆ‘ä¼šè®°ä½æˆ‘ä»¬çš„å¯¹è¯å†å²
    """
    else:
        welcome_msg += """
    **âš ï¸ AIæ¨¡å‹çŠ¶æ€**ï¼š
    - âŒ æœªæ£€æµ‹åˆ°APIå¯†é’¥ï¼Œè‡ªç„¶è¯­è¨€å¯¹è¯åŠŸèƒ½ä¸å¯ç”¨
    - ğŸ’¡ æ‚¨ä»å¯ä½¿ç”¨æ‰€æœ‰å¿«é€Ÿæ“ä½œæŒ‰é’®è¿›è¡Œåˆ†æ
    - ğŸ”§ è¯·åœ¨ä¾§è¾¹æ æŸ¥çœ‹APIé…ç½®è¯´æ˜
    """

    st.markdown(welcome_msg)

def build_main_content():
    """æ„å»ºä¸»è¦å†…å®¹åŒºåŸŸ"""
    # ä½¿ç”¨åŒæ å¸ƒå±€
    col_chat, col_result = st.columns([0.6, 0.4], gap="large")
    
    with col_chat:
        st.subheader("ğŸ’¬ å¯¹è¯åŒºåŸŸ")
        build_chat_area()
    
    with col_result:
        st.subheader("ğŸ“Š ç»“æœå±•ç¤º")
        build_result_tabs()

def build_result_tabs():
    """æ„å»ºç»“æœæ ‡ç­¾é¡µ"""
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab_overview, tab_qc, tab_preprocess, tab_reduce, tab_cluster, tab_marker = st.tabs([
        "ğŸ“‹ æ¦‚è§ˆ", "ğŸ©º è´¨æ§", "âš™ï¸ é¢„å¤„ç†", "ğŸ“‰ é™ç»´", "ğŸ¯ èšç±»", "ğŸ§¬ æ ‡è®°åŸºå› "
    ])
    
    with tab_overview:
        _render_overview_tab()
    
    with tab_qc:
        _render_filtered_messages("quality_control")
    
    with tab_preprocess:
        _render_filtered_messages("preprocessing")
    
    with tab_reduce:
        _render_filtered_messages("dimensionality_reduction")
    
    with tab_cluster:
        _render_filtered_messages("clustering")
    
    with tab_marker:
        _render_filtered_messages("marker_genes")

def _render_overview_tab():
    """æ¸²æŸ“æ¦‚è§ˆæ ‡ç­¾é¡µ"""
    if st.session_state.messages:
        st.info(f"ğŸ’¬ å½“å‰å¯¹è¯åŒ…å« {len(st.session_state.messages)} æ¡æ¶ˆæ¯")
        
        # ç»Ÿè®¡ä¸åŒç±»å‹çš„æ¶ˆæ¯
        user_msgs = sum(1 for msg in st.session_state.messages if isinstance(msg, HumanMessage))
        ai_msgs = sum(1 for msg in st.session_state.messages if isinstance(msg, AIMessage))
        tool_msgs = sum(1 for msg in st.session_state.messages if isinstance(msg, ToolMessage))
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ç”¨æˆ·æ¶ˆæ¯", user_msgs, help="æ‚¨å‘é€çš„æ¶ˆæ¯æ•°é‡")
        with col2:
            st.metric("AIå›å¤", ai_msgs, help="AIåŠ©æ‰‹çš„å›å¤æ•°é‡")
        with col3:
            st.metric("å·¥å…·æ‰§è¡Œ", tool_msgs, help="æ‰§è¡Œçš„å·¥å…·æ•°é‡")
        
        # æ˜¾ç¤ºæœ€è¿‘çš„å›¾ç‰‡
        recent_images = []
        for msg in reversed(st.session_state.messages):
            if isinstance(msg, ToolMessage):
                content = msg.content
                if isinstance(content, str):
                    clean_content, artifacts = extract_artifacts_from_content(content)
                    if artifacts:
                        recent_images.extend(artifacts)
                        if len(recent_images) >= 4:  # æœ€å¤šæ˜¾ç¤º4å¼ å›¾ç‰‡
                            break
        
        if recent_images:
            st.write("**æœ€è¿‘ç”Ÿæˆçš„å›¾è¡¨ï¼š**")
            cols = st.columns(2)
            for i, rel_path in enumerate(recent_images[:4]):
                if rel_path.endswith(".png"):
                    abs_path = os.path.join(
                        os.path.dirname(os.path.dirname(__file__)),
                        "3_backend_mcp",
                        rel_path
                    )
                    if os.path.exists(abs_path):
                        with cols[i % 2]:
                            st.image(abs_path, caption=os.path.basename(rel_path), width=200)
    else:
        st.info("ğŸš€ å¼€å§‹æ‚¨çš„åˆ†æä¹‹æ—…ï¼ä½¿ç”¨ä¾§è¾¹æ çš„å¿«é€Ÿæ“ä½œæˆ–åœ¨ä¸‹æ–¹è¾“å…¥é—®é¢˜ã€‚")

def _render_filtered_messages(filter_type: str):
    """æ¸²æŸ“è¿‡æ»¤åçš„æ¶ˆæ¯"""
    filtered_messages = []
    
    for msg in st.session_state.messages:
        if isinstance(msg, ToolMessage):
            tool_name = getattr(msg, 'name', '').lower()
            if filter_type in tool_name:
                filtered_messages.append(msg)
    
    if filtered_messages:
        for i, msg in enumerate(filtered_messages):
            display_message(msg, i)
    else:
        st.info(f"æš‚æ—  {filter_type} ç›¸å…³çš„ç»“æœã€‚è¯·å…ˆæ‰§è¡Œç›¸åº”çš„åˆ†ææ­¥éª¤ã€‚")

# ========= ä¸šåŠ¡é€»è¾‘å‡½æ•° =========

# æ„å»º ToolMessage è¾…åŠ©å‡½æ•°


def build_tool_message(tool_name: str, result: Dict[str, Any]) -> ToolMessage:
    """æ ¹æ®MCPè¿”å›ç»“æœæ„é€ åŒ…å«éšæœºtool_call_idçš„ToolMessage"""
    return ToolMessage(
        content=result.get("content", ""),
        tool_call_id=str(uuid4()),
        name=tool_name,
        artifact=result.get("artifact", [])
    )

# MCPå·¥å…·è°ƒç”¨å‡½æ•°


def parse_mcp_result(result):
    """è§£æMCPå·¥å…·è¿”å›çš„ç»“æœ"""
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰contentå­—æ®µ
        if hasattr(result, 'content') and result.content:
            # è·å–ç¬¬ä¸€ä¸ªTextContentçš„æ–‡æœ¬å†…å®¹
            text_content = result.content[0].text
            # å°è¯•è§£æJSON
            try:
                parsed = json.loads(text_content)
                return parsed
            except json.JSONDecodeError:
                # å¦‚æœä¸æ˜¯JSONï¼Œç›´æ¥è¿”å›æ–‡æœ¬
                return {"content": text_content}
        else:
            return {"error": "No content in result"}
    except Exception as e:
        return {"error": f"è§£æç»“æœå¤±è´¥: {e}"}


def call_mcp_tool_sync(tool_name: str, arguments: Dict[str, Any]) -> Any:
    """åŒæ­¥è°ƒç”¨MCPå·¥å…· - ä½¿ç”¨æ­£ç¡®çš„SSEå®¢æˆ·ç«¯è¿æ¥æ–¹å¼"""
    try:
        logger.info(f"[MCPè°ƒç”¨] å·¥å…·: {tool_name}, å‚æ•°: {arguments}")
        result = asyncio.run(call_mcp_tool(tool_name, arguments))
        logger.info(f"[MCPè¿”å›] å·¥å…·: {tool_name}, è¿”å›ç±»å‹: {type(result)}")

        # è§£æMCPç»“æœ
        parsed_result = parse_mcp_result(result)
        logger.info(f"[MCPè§£æ] å·¥å…·: {tool_name}, è§£æå: {parsed_result}")
        return parsed_result
    except Exception as e:
        logger.error(f"è°ƒç”¨MCPå·¥å…·å¤±è´¥: {e}")
        return {"error": f"è¿æ¥MCPæœåŠ¡å™¨å¤±è´¥: {str(e)}"}


async def call_mcp_tool(tool_name: str, arguments: Dict[str, Any]) -> Any:
    """å¼‚æ­¥è°ƒç”¨MCPå·¥å…·"""
    async with sse_client(MCP_SERVER_URL) as (read, write):
        async with ClientSession(read, write) as session:
            await session.initialize()
            result = await session.call_tool(tool_name, arguments)
            return result


def check_mcp_server_health() -> bool:
    """æ£€æŸ¥MCPæœåŠ¡å™¨å¥åº·çŠ¶æ€"""
    try:
        result = call_mcp_tool_sync("health_check", {})
        # æ£€æŸ¥è§£æåçš„ç»“æœ
        return isinstance(result, dict) and not result.get("error") and result.get("status") == "healthy"
    except Exception as e:
        logger.error(f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        return False


def get_llm_client(model_name: str = "gpt-4o"):
    """æ ¹æ®æ¨¡å‹åç§°è¿”å›ç›¸åº”çš„LLMå®¢æˆ·ç«¯"""
    if model_name.startswith("deepseek"):
        deepseek_api_key = os.environ.get("DEEPSEEK_API_KEY")
        if not deepseek_api_key:
            raise ValueError("DEEPSEEK_API_KEY environment variable not set")

        base_url = "https://www.chataiapi.com/v1"

        return ChatOpenAI(
            model=model_name,
            temperature=0,
            api_key=SecretStr(deepseek_api_key),
            base_url=base_url
        )
    else:
        openai_api_key = os.environ.get("OPENAI_API_KEY")
        if not openai_api_key:
            raise ValueError("OPENAI_API_KEY environment variable not set")

        return ChatOpenAI(
            model=model_name,
            temperature=0,
            api_key=SecretStr(openai_api_key)
        )


def is_python_code(text: str) -> bool:
    """åˆ¤æ–­æ–‡æœ¬æ˜¯å¦ä¸ºPythonä»£ç """
    if not text or not isinstance(text, str):
        return False

    text = text.strip()
    python_indicators = [
        "import ", "from ", "def ", "class ", "plt.show()", "plt.figure",
        "sc.pl.", "adata = ", "pd.DataFrame", "np.", "matplotlib", "scanpy"
    ]

    if text.startswith("import ") or text.startswith("from "):
        return True

    if "plt.show()" in text or "plt.figure" in text:
        return True

    indicator_count = sum(
        1 for indicator in python_indicators if indicator in text)
    return indicator_count >= 2


def extract_artifacts_from_content(content: str) -> tuple[str, list]:
    """ä»å†…å®¹ä¸­æå–å›¾ç‰‡è·¯å¾„ä¿¡æ¯"""
    import re

    # æŸ¥æ‰¾[ARTIFACTS]æ ‡è®°
    pattern = r'\[ARTIFACTS\](.*?)\[/ARTIFACTS\]'
    match = re.search(pattern, content)

    if match:
        try:
            artifacts_json = match.group(1)
            artifacts = json.loads(artifacts_json)
            # ç§»é™¤æ ‡è®°ï¼Œè¿”å›æ¸…æ´çš„å†…å®¹
            clean_content = re.sub(pattern, '', content).strip()
            return clean_content, artifacts
        except json.JSONDecodeError:
            return content, []

    return content, []


def display_message(message: BaseMessage, index: int):
    """æ˜¾ç¤ºå•æ¡æ¶ˆæ¯ - ç¾åŒ–ç‰ˆæœ¬ï¼Œä¸åŒç±»å‹æ¶ˆæ¯ä½¿ç”¨ä¸åŒé¢œè‰²"""
    # è·å–ç”¨æˆ·è®¾ç½®çš„å›¾ç‰‡å®½åº¦ï¼Œé»˜è®¤ä¸º700
    img_width = getattr(st.session_state, 'image_width', 700)

    with st.container():
        if isinstance(message, HumanMessage):
            st.markdown('<div class="chat-message user-message">',
                        unsafe_allow_html=True)
            st.markdown('<p class="message-label user-label">ğŸ‘¤ ç”¨æˆ·:</p>', unsafe_allow_html=True)
            
            # æ­£ç¡®å¤„ç†HumanMessageçš„å†…å®¹
            if isinstance(message.content, str):
                st.write(message.content)
            elif isinstance(message.content, list):
                # å¤„ç†åŒ…å«æ–‡æœ¬å’Œå›¾ç‰‡çš„åˆ—è¡¨å†…å®¹
                for item in message.content:
                    if isinstance(item, dict):
                        if item.get("type") == "text":
                            st.write(item["text"])
                        elif item.get("type") == "image_url":
                            if "image_url" in item and "url" in item["image_url"]:
                                st.image(item["image_url"]["url"], caption="ç”¨æˆ·ä¸Šä¼ çš„å›¾ç‰‡")
                    elif isinstance(item, str):
                        st.write(item)
            else:
                # å¦‚æœå†…å®¹æ˜¯å…¶ä»–ç±»å‹ï¼Œç›´æ¥æ˜¾ç¤º
                st.write(str(message.content))
            
            st.markdown('</div>', unsafe_allow_html=True)

        elif isinstance(message, AIMessage):
            # åˆ¤æ–­æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            has_tool_calls = hasattr(message, 'tool_calls') and message.tool_calls
            
            # æ ¹æ®æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨é€‰æ‹©ä¸åŒçš„CSSç±»
            if has_tool_calls:
                st.markdown('<div class="chat-message assistant-message-with-tools">',
                            unsafe_allow_html=True)
                st.markdown('<p class="message-label assistant-label-with-tools">ğŸ¤– åŠ©æ‰‹ (å‡†å¤‡è°ƒç”¨å·¥å…·):</p>', 
                           unsafe_allow_html=True)
            else:
                st.markdown('<div class="chat-message assistant-message">',
                            unsafe_allow_html=True)
                st.markdown('<p class="message-label assistant-label">ğŸ¤– åŠ©æ‰‹:</p>', unsafe_allow_html=True)

            # æ­£ç¡®å¤„ç†AIMessageçš„å†…å®¹
            content = message.content
            if isinstance(content, str):
                # è§£æå†…å®¹ä¸­çš„å›¾ç‰‡è·¯å¾„ä¿¡æ¯
                clean_content, artifacts = extract_artifacts_from_content(content)
                
                if clean_content:
                    # å¤„ç†LaTeXæ ¼å¼
                    modified_content = clean_content.replace("\\(", "$").replace("\\)", "$")
                    modified_content = modified_content.replace("\\[", "$$").replace("\\]", "$$")
                    st.markdown(modified_content)
                
                # æ˜¾ç¤ºå›¾ç‰‡ï¼ˆå¦‚æœæœ‰ï¼‰
                if artifacts:
                    st.write("**ç”Ÿæˆçš„å›¾è¡¨:**")
                    for rel_path in artifacts:
                        if rel_path.endswith(".png"):
                            abs_path = os.path.join(
                                os.path.dirname(os.path.dirname(__file__)),
                                "3_backend_mcp",
                                rel_path
                            )
                            if os.path.exists(abs_path):
                                st.image(
                                    abs_path,
                                    caption=f"ç”Ÿæˆçš„å›¾è¡¨: {os.path.basename(rel_path)}",
                                    width=img_width
                                )
                            else:
                                st.error(f"å›¾ç‰‡æ–‡ä»¶æœªæ‰¾åˆ°: {rel_path}")
                                
            elif isinstance(content, list):
                # å¤„ç†åˆ—è¡¨å†…å®¹
                for item in content:
                    if isinstance(item, dict):
                        if item.get("type") == "text" and "text" in item:
                            modified_text = item["text"].replace("\\(", "$").replace("\\)", "$")
                            modified_text = modified_text.replace("\\[", "$$").replace("\\]", "$$")
                            st.markdown(modified_text)
                        elif "url" in item:
                            st.image(item["url"], caption="åŠ©æ‰‹ç”Ÿæˆçš„å›¾ç‰‡")
                    elif isinstance(item, str):
                        modified_content = item.replace("\\(", "$").replace("\\)", "$")
                        modified_content = modified_content.replace("\\[", "$$").replace("\\]", "$$")
                        st.markdown(modified_content)
            else:
                # å¤„ç†å…¶ä»–ç±»å‹çš„å†…å®¹
                st.write(str(content))

            # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨è¯·æ±‚
            if has_tool_calls:
                st.markdown("**ğŸ”§ å·¥å…·è°ƒç”¨è¯·æ±‚:**")
                for i, tool_call in enumerate(message.tool_calls):
                    # æ£€æŸ¥æ˜¯å¦æ˜¯Python REPLå·¥å…·ï¼Œç¡®ä¿éœ€è¦ç”¨æˆ·ç¡®è®¤
                    if "python_repl_tool" in tool_call.get("name", ""):
                        # ç¡®ä¿å·¥å…·è°ƒç”¨æœ‰requires_confirmationæ ‡è®°
                        tool_call["requires_confirmation"] = True
                    render_tool_call_pending(tool_call, index, i)

            st.markdown('</div>', unsafe_allow_html=True)

        elif isinstance(message, ToolMessage):
            st.markdown('<div class="chat-message tool-message">',
                        unsafe_allow_html=True)
            tool_name = getattr(message, 'name', 'Unknown Tool')
            st.markdown(f'<p class="message-label tool-label">ğŸ”§ å·¥å…·: {tool_name}</p>', unsafe_allow_html=True)

            content = message.content

            if isinstance(content, str):
                # è§£æå†…å®¹ä¸­çš„å›¾ç‰‡è·¯å¾„ä¿¡æ¯
                clean_content, artifacts = extract_artifacts_from_content(content)

                if is_python_code(clean_content):
                    st.markdown("**æ‰§è¡Œçš„ä»£ç :**")
                    st.code(clean_content, language="python")
                    
                    # æ˜¾ç¤ºæ‰§è¡Œç»“æœ
                    st.markdown("**æ‰§è¡Œç»“æœ:**")
                    # å¦‚æœå†…å®¹çœ‹èµ·æ¥åƒé”™è¯¯ä¿¡æ¯ï¼Œç”¨é”™è¯¯æ ·å¼æ˜¾ç¤º
                    if "Error:" in clean_content or "Exception:" in clean_content:
                        st.error(clean_content)
                    else:
                        st.text(clean_content)
                        
                else:
                    st.write(clean_content)

                # æ˜¾ç¤ºå·¥å…·è¿”å›çš„å›¾ç‰‡
                if artifacts:
                    st.write("**ç”Ÿæˆçš„å›¾è¡¨:**")
                    for rel_path in artifacts:
                        if rel_path.endswith(".png"):
                            abs_path = os.path.join(
                                os.path.dirname(os.path.dirname(__file__)),
                                "3_backend_mcp",
                                rel_path
                            )
                            if os.path.exists(abs_path):
                                st.image(
                                    abs_path,
                                    caption=f"ç”Ÿæˆçš„å›¾è¡¨: {os.path.basename(rel_path)}",
                                    width=img_width
                                )
                            else:
                                st.error(f"å›¾ç‰‡æ–‡ä»¶æœªæ‰¾åˆ°: {rel_path}")
                                st.info(f"é¢„æœŸè·¯å¾„: {abs_path}")
            else:
                st.write(str(content))

            # æ˜¾ç¤ºå·¥å…·è¿”å›çš„å›¾ç‰‡ï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ä½œä¸ºå¤‡ç”¨ï¼‰
            tool_artifacts = getattr(message, 'artifact', [])
            if tool_artifacts:
                st.write("**ç”Ÿæˆçš„å›¾è¡¨:**")
                for rel_path in tool_artifacts:
                    if rel_path.endswith(".png"):
                        abs_path = os.path.join(
                            os.path.dirname(os.path.dirname(__file__)),
                            "3_backend_mcp",
                            rel_path
                        )
                        if os.path.exists(abs_path):
                            st.image(
                                abs_path,
                                caption=f"ç”Ÿæˆçš„å›¾è¡¨: {os.path.basename(rel_path)}",
                                width=img_width
                            )
                        else:
                            st.error(f"å›¾ç‰‡æ–‡ä»¶æœªæ‰¾åˆ°: {rel_path}")

            st.markdown('</div>', unsafe_allow_html=True)


# åºåˆ—åŒ–å’Œååºåˆ—åŒ–å‡½æ•°
def serialize_message(message: BaseMessage) -> Dict[str, Any]:
    """å°†BaseMessageåºåˆ—åŒ–ä¸ºå­—å…¸"""
    result = {
        "type": type(message).__name__,
        "content": message.content,
    }
    
    if hasattr(message, "tool_call_id"):
        result["tool_call_id"] = message.tool_call_id
    if hasattr(message, "name"):
        result["name"] = message.name
    if hasattr(message, "artifact"):
        result["artifact"] = message.artifact
    if hasattr(message, "tool_calls"):
        result["tool_calls"] = message.tool_calls
        
    return result

def deserialize_message(data: Dict[str, Any]) -> BaseMessage:
    """å°†å­—å…¸ååºåˆ—åŒ–ä¸ºBaseMessage"""
    msg_type = data["type"]
    content = data["content"]
    
    if msg_type == "HumanMessage":
        return HumanMessage(content=content)
    elif msg_type == "AIMessage":
        msg = AIMessage(content=content)
        if "tool_calls" in data:
            msg.tool_calls = data["tool_calls"]
        return msg
    elif msg_type == "ToolMessage":
        return ToolMessage(
            content=content,
            tool_call_id=data.get("tool_call_id", ""),
            name=data.get("name", ""),
            artifact=data.get("artifact", [])
        )
    elif msg_type == "SystemMessage":
        return SystemMessage(content=content)
    else:
        # é»˜è®¤è¿”å›HumanMessage
        return HumanMessage(content=content)

# åˆå§‹åŒ–session state
if "conversation_id" not in st.session_state:
    st.session_state.conversation_id = None
if "messages" not in st.session_state:
    st.session_state.messages = []
if "conversation_history" not in st.session_state:
    st.session_state.conversation_history = []
if "run_counter" not in st.session_state:
    st.session_state.run_counter = 0
if "pending_tool_calls" not in st.session_state:
    st.session_state.pending_tool_calls = {}
if "image_width" not in st.session_state:
    st.session_state.image_width = 700


def get_available_models():
    """æ ¹æ®APIå¯†é’¥è‡ªåŠ¨æ£€æµ‹å¯ç”¨æ¨¡å‹"""
    openai_key = os.getenv("OPENAI_API_KEY")
    deepseek_key = os.getenv("DEEPSEEK_API_KEY")

    available_models = {}

    # æ£€æŸ¥OpenAI API
    if openai_key:
        available_models.update({
            "OpenAI GPT-4o": "gpt-4o",
            "OpenAI GPT-4 Turbo": "gpt-4-turbo"
        })

    # æ£€æŸ¥DeepSeek API
    if deepseek_key:
        available_models.update({
            "DeepSeek Chat": "deepseek-chat"
        })

    return available_models, openai_key, deepseek_key


# å¦‚æœå‰é¢æ²¡æœ‰å®šä¹‰ call_agent_core_sync / check_agent_core_healthï¼Œåˆ™è¡¥å……å®šä¹‰
if 'call_agent_core_sync' not in globals():
    def call_agent_core_sync(message: str, conversation_id: str = None) -> Dict[str, Any]:
        """è°ƒç”¨Agent Coreå¤„ç†æ¶ˆæ¯ï¼Œæ”¯æŒå¯¹è¯è®°å¿†"""
        try:
            payload = {"message": message}
            if conversation_id:
                payload["conversation_id"] = conversation_id
                
            resp = requests.post(AGENT_CORE_CHAT_URL, json=payload, timeout=120)
            resp.raise_for_status()
            return resp.json()
        except Exception as e:
            logger.error(f"è°ƒç”¨ Agent Core å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}

if 'check_agent_core_health' not in globals():
    def check_agent_core_health() -> bool:
        try:
            resp = requests.get("http://localhost:8002/health", timeout=10)
            return resp.status_code == 200 and resp.json().get("status") == "healthy"
        except Exception:
            return False

def get_conversations() -> List[Dict[str, Any]]:
    """è·å–æ‰€æœ‰å¯¹è¯åˆ—è¡¨"""
    try:
        resp = requests.get(AGENT_CORE_CONVERSATIONS_URL, timeout=10)
        resp.raise_for_status()
        return resp.json().get("conversations", [])
    except Exception as e:
        logger.error(f"è·å–å¯¹è¯åˆ—è¡¨å¤±è´¥: {e}")
        return []

def delete_conversation(conversation_id: str) -> bool:
    """åˆ é™¤å¯¹è¯"""
    try:
        resp = requests.delete(f"{AGENT_CORE_CONVERSATIONS_URL}/{conversation_id}", timeout=10)
        resp.raise_for_status()
        return True
    except Exception as e:
        logger.error(f"åˆ é™¤å¯¹è¯å¤±è´¥: {e}")
        return False

def clear_conversation(conversation_id: str) -> bool:
    """æ¸…ç©ºå¯¹è¯"""
    try:
        resp = requests.post(f"{AGENT_CORE_CONVERSATIONS_URL}/{conversation_id}/clear", timeout=10)
        resp.raise_for_status()
        return True
    except Exception as e:
        logger.error(f"æ¸…ç©ºå¯¹è¯å¤±è´¥: {e}")
        return False

# ========= ä¸»ç¨‹åºå…¥å£ =========

def main():
    """ä¸»ç¨‹åºå…¥å£"""
    # æ³¨å…¥æ ·å¼
    inject_global_style()
    
    # æ„å»ºé¡µé¢å¤´éƒ¨
    build_header()
    
    # æ„å»ºä¾§è¾¹æ å¹¶è·å–é…ç½®
    selected_model, selected_model_name, server_online, agent_online = build_sidebar()
    
    # æ„å»ºä¸»è¦å†…å®¹åŒºåŸŸ
    build_main_content()
    
    # èŠå¤©è¾“å…¥å¤„ç†
    handle_chat_input(selected_model, selected_model_name, server_online, agent_online)
    
    # é¡µé¢åº•éƒ¨ä¿¡æ¯
    build_footer()

def handle_chat_input(selected_model, selected_model_name, server_online, agent_online):
    """å¤„ç†èŠå¤©è¾“å…¥"""
    if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼Œæ¯”å¦‚'è¯·åˆ†æPBMC3Kæ•°æ®çš„èšç±»ç»“æœ'..."):
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        st.session_state.messages.append(HumanMessage(content=prompt))

        # ç®€å•çš„æ„å›¾è¯†åˆ«å’ŒMCPå·¥å…·è°ƒç”¨
        prompt_lower = prompt.lower()
        direct_mcp_call = False
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºç›´æ¥MCPå·¥å…·è°ƒç”¨çš„ç®€å•é—®é¢˜
        if "åŠ è½½" in prompt and ("æ•°æ®" in prompt or "pbmc" in prompt_lower):
            _execute_mcp_tool("load_pbmc3k_data", "æ­£åœ¨è·å–æ•°æ®åŠ è½½ä»£ç ...")
            direct_mcp_call = True
        elif "è´¨é‡æ§åˆ¶" in prompt or "è´¨æ§" in prompt:
            _execute_mcp_tool("quality_control_analysis", "æ­£åœ¨è·å–è´¨é‡æ§åˆ¶åˆ†æä»£ç ...")
            direct_mcp_call = True
        elif "é¢„å¤„ç†" in prompt:
            _execute_mcp_tool("preprocessing_analysis", "æ­£åœ¨è·å–æ•°æ®é¢„å¤„ç†ä»£ç ...")
            direct_mcp_call = True
        elif "é™ç»´" in prompt or "pca" in prompt_lower or "umap" in prompt_lower:
            _execute_mcp_tool("dimensionality_reduction_analysis", "æ­£åœ¨è·å–é™ç»´åˆ†æä»£ç ...")
            direct_mcp_call = True
        elif "èšç±»" in prompt or "clustering" in prompt_lower:
            _execute_mcp_tool("clustering_analysis", "æ­£åœ¨è·å–èšç±»åˆ†æä»£ç ...")
            direct_mcp_call = True
        elif "æ ‡è®°åŸºå› " in prompt or "marker" in prompt_lower:
            _execute_mcp_tool("marker_genes_analysis", "æ­£åœ¨è·å–æ ‡è®°åŸºå› åˆ†æä»£ç ...")
            direct_mcp_call = True
        elif "æŠ¥å‘Š" in prompt or "æ€»ç»“" in prompt:
            _execute_mcp_tool("generate_analysis_report", "æ­£åœ¨ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
            direct_mcp_call = True

        # å¦‚æœä¸æ˜¯ç›´æ¥MCPè°ƒç”¨ï¼Œåˆ™ä½¿ç”¨Agent Coreå¤„ç†ï¼ˆæ”¯æŒå¯¹è¯è®°å¿†ï¼‰
        if not direct_mcp_call:
            if agent_online:
                with st.spinner("ğŸ¤– Agentæ­£åœ¨æ€è€ƒæ‚¨çš„é—®é¢˜..."):
                    result = call_agent_core_sync(prompt, st.session_state.conversation_id)
                    if result.get("success"):
                        # æ›´æ–°conversation_id
                        st.session_state.conversation_id = result.get("conversation_id")

                        # å¤„ç†Agent Coreè¿”å›çš„å®Œæ•´æ¶ˆæ¯åˆ—è¡¨
                        returned_messages = result.get("messages", [])

                        if returned_messages:
                            # æ™ºèƒ½å¤„ç†Agent Coreè¿”å›çš„æ¶ˆæ¯ï¼Œé¿å…é‡å¤
                            current_messages = st.session_state.messages.copy()
                            
                            # åªæ·»åŠ Agentè¿”å›çš„æ–°æ¶ˆæ¯
                            for msg_data in returned_messages:
                                try:
                                    msg_obj = deserialize_message(msg_data)
                                    
                                    # è·³è¿‡ç”¨æˆ·æ¶ˆæ¯ï¼Œå› ä¸ºç”¨æˆ·æ¶ˆæ¯å·²ç»åœ¨å‰ç«¯æ·»åŠ äº†
                                    if isinstance(msg_obj, HumanMessage):
                                        continue
                                    
                                    # æ£€æŸ¥æ˜¯å¦ä¸ºéœ€è¦ç”¨æˆ·ç¡®è®¤çš„å·¥å…·è°ƒç”¨æ¶ˆæ¯
                                    if (isinstance(msg_obj, AIMessage) and 
                                        hasattr(msg_obj, 'tool_calls') and 
                                        msg_obj.tool_calls and
                                        any(tool.get('name', '').endswith('python_repl_tool') for tool in msg_obj.tool_calls)):
                                        
                                        # æ ‡è®°éœ€è¦ç”¨æˆ·ç¡®è®¤çš„å·¥å…·è°ƒç”¨
                                        for tool_call in msg_obj.tool_calls:
                                            if tool_call.get('name', '').endswith('python_repl_tool'):
                                                tool_call['requires_confirmation'] = True
                                    
                                    # æ™ºèƒ½å»é‡ï¼šæ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨ç›¸åŒçš„æ¶ˆæ¯
                                    is_duplicate = False
                                    for existing_msg in current_messages:
                                        if (isinstance(existing_msg, type(msg_obj)) and 
                                            getattr(existing_msg, 'content', '') == getattr(msg_obj, 'content', '')):
                                            
                                            # å¯¹äºAIMessageï¼Œè¿˜è¦æ£€æŸ¥tool_callsæ˜¯å¦ç›¸åŒ
                                            if isinstance(msg_obj, AIMessage) and hasattr(msg_obj, 'tool_calls'):
                                                if (hasattr(existing_msg, 'tool_calls') and 
                                                    existing_msg.tool_calls == msg_obj.tool_calls):
                                                    is_duplicate = True
                                                    break
                                            else:
                                                is_duplicate = True
                                                break
                                    
                                    # åªæœ‰éé‡å¤çš„æ¶ˆæ¯æ‰æ·»åŠ 
                                    if not is_duplicate:
                                        current_messages.append(msg_obj)
                                        
                                except Exception as e:
                                    # å›é€€åˆ°çº¯æ–‡æœ¬
                                    logger.error(f"æ¶ˆæ¯ååºåˆ—åŒ–å¤±è´¥: {e}")
                                    current_messages.append(AIMessage(content=str(msg_data)))
                            
                            # æ›´æ–°session state
                            st.session_state.messages = current_messages
                        else:
                            # å…¼å®¹æ—§ç‰ˆï¼šä»…æœ‰final_response
                            ai_message = AIMessage(content=result.get("final_response", ""))
                            st.session_state.messages.append(ai_message)
                    else:
                        error_msg = result.get("error", "æœªçŸ¥é”™è¯¯")
                        st.session_state.messages.append(
                            AIMessage(content=f"Agent Coreé”™è¯¯: {error_msg}"))
            else:
                st.session_state.messages.append(
                    AIMessage(content="âš ï¸ Agent Coreæœªå¯åŠ¨ï¼Œæ— æ³•å¤„ç†è¯¥è¯·æ±‚ã€‚"))

        st.rerun()

def render_tool_call_pending(tool_call, message_index: int, tool_index: int):
    """æ¸²æŸ“å¾…ç¡®è®¤çš„å·¥å…·è°ƒç”¨ - ç¾åŒ–ç‰ˆæœ¬"""
    tool_name = tool_call.get("name", "unknown_tool")
    args = tool_call.get("args", {})
    tool_id = tool_call.get("id", f"tool_{message_index}_{tool_index}")
    requires_confirmation = tool_call.get("requires_confirmation", False)
    
    # åˆ›å»ºæ›´å”¯ä¸€çš„é”®ï¼ŒåŒ…å«å·¥å…·è°ƒç”¨çš„å®Œæ•´ä¿¡æ¯
    tool_signature = f"{tool_name}_{tool_id}_{hash(str(args))}"
    unique_key = f"tool_{message_index}_{tool_index}_{tool_signature}"
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»æ‰§è¡Œè¿‡
    executed_key = f"executed_{unique_key}"
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»æ‰§è¡Œè¿‡ï¼ˆé€šè¿‡session stateæˆ–æ¶ˆæ¯å†å²ï¼‰
    is_executed = False
    if executed_key in st.session_state and st.session_state[executed_key]:
        is_executed = True
    else:
        # æ£€æŸ¥æ¶ˆæ¯å†å²ä¸­æ˜¯å¦æœ‰å¯¹åº”çš„ToolMessageï¼ˆæ’é™¤å ä½ç¬¦æ¶ˆæ¯ï¼‰
        for msg in st.session_state.messages:
            if (isinstance(msg, ToolMessage) and 
                getattr(msg, 'tool_call_id', '') == tool_id and
                getattr(msg, 'name', '') == tool_name):
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯å ä½ç¬¦æ¶ˆæ¯
                content = getattr(msg, 'content', '')
                if content == "[ç­‰å¾…ç”¨æˆ·ç¡®è®¤æ‰§è¡Œ]":
                    # è¿™æ˜¯å ä½ç¬¦æ¶ˆæ¯ï¼Œä¸ç®—ä½œå·²æ‰§è¡Œ
                    continue
                else:
                    # è¿™æ˜¯çœŸæ­£çš„æ‰§è¡Œç»“æœ
                    is_executed = True
                    # æ›´æ–°session stateä»¥ä¿æŒä¸€è‡´æ€§
                    st.session_state[executed_key] = True
                    break
    
    if is_executed:
        # ä½¿ç”¨æ‰§è¡Œå®Œæˆçš„æ ·å¼ï¼Œä½†ä»ç„¶æ˜¾ç¤ºä»£ç 
        st.markdown('<div class="tool-executed">', unsafe_allow_html=True)
        st.markdown(f'<h4 style="color: #2e7d32; margin-bottom: 12px;">âœ… å·¥å…·å·²æ‰§è¡Œ: {tool_name}</h4>', 
                    unsafe_allow_html=True)
        
        # æ˜¾ç¤ºæ‰§è¡Œçš„ä»£ç 
        if args and "query" in args:
            st.markdown("**å·²æ‰§è¡Œçš„ä»£ç :**")
            st.code(args["query"], language="python")
        elif args:
            st.markdown("**æ‰§è¡Œå‚æ•°:**")
            st.json(args)
        
        st.markdown('</div>', unsafe_allow_html=True)
        return
    
    # ä½¿ç”¨å·¥å…·è°ƒç”¨ç­‰å¾…çŠ¶æ€çš„æ ·å¼
    st.markdown('<div class="tool-pending">', unsafe_allow_html=True)
    st.markdown(f'<h4 style="color: #7b1fa2; margin-bottom: 12px;">ğŸ”§ å·¥å…·è°ƒç”¨: {tool_name}</h4>', 
                unsafe_allow_html=True)
    
    # æ˜¾ç¤ºå‚æ•°
    if args:
        st.markdown("**å‚æ•°:**")
        if "query" in args:
            st.markdown("**è¦æ‰§è¡Œçš„ä»£ç :**")
            st.code(args["query"], language="python")
        else:
            st.json(args)
    
    # åˆ›å»ºæŒ‰é’®åˆ—
    col1, col2, col3 = st.columns([1, 1, 4])
    
    # ä½¿ç”¨æ›´ç¨³å®šçš„æŒ‰é’®é”®ï¼ŒåŸºäºå·¥å…·è°ƒç”¨çš„å”¯ä¸€æ ‡è¯†
    run_key = f"run_{unique_key}"
    cancel_key = f"cancel_{unique_key}"
    
    # å¯¹äºpython_repl_toolï¼Œå¿…é¡»è¦æ±‚ç”¨æˆ·ç¡®è®¤
    is_python_repl = "python_repl_tool" in tool_name
    
    # æ‰§è¡ŒæŒ‰é’®
    if col1.button("â–¶ï¸ æ‰§è¡Œ", key=run_key, help="æ‰§è¡Œæ­¤å·¥å…·è°ƒç”¨", 
                   type="primary", use_container_width=True):
        with st.spinner("ğŸ”„ æ­£åœ¨æ‰§è¡Œå·¥å…·..."):
            start_time = time.time()
            
            try:
                # æ‰§è¡Œå·¥å…·
                result = call_mcp_tool_sync(tool_name, args)
                exec_time = time.time() - start_time
                
                # ç”ŸæˆToolMessage
                tool_msg = build_tool_message(tool_name, result)
                
                # æ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨
                st.session_state.messages.append(tool_msg)
                
                # æ ‡è®°ä¸ºå·²æ‰§è¡Œ
                st.session_state[executed_key] = True
                
                # æ˜¾ç¤ºæ‰§è¡Œç»“æœ
                st.success(f"âœ… å·¥å…·æ‰§è¡Œå®Œæˆ (è€—æ—¶: {exec_time:.2f}s)")
                
                # å¦‚æœæœ‰é”™è¯¯ï¼Œæ˜¾ç¤ºé”™è¯¯
                if isinstance(result, dict) and result.get("error"):
                    st.error(f"âŒ æ‰§è¡Œé”™è¯¯: {result['error']}")
                else:
                    result_preview = str(result.get('content', 'æ— è¾“å‡º') if isinstance(result, dict) else result)[:100]
                    st.info(f"ğŸ“¤ æ‰§è¡Œç»“æœ: {result_preview}...")
                
                # é‡æ–°è¿è¡Œä»¥åˆ·æ–°ç•Œé¢
                st.rerun()
                
            except Exception as e:
                st.error(f"âŒ æ‰§è¡Œå¤±è´¥: {str(e)}")
                logger.error(f"å·¥å…·æ‰§è¡Œå¤±è´¥: {e}")
    
    # å–æ¶ˆæŒ‰é’®
    if col2.button("âŒ å–æ¶ˆ", key=cancel_key, help="å–æ¶ˆæ­¤å·¥å…·è°ƒç”¨", 
                   use_container_width=True):
        # åˆ›å»ºå–æ¶ˆæ¶ˆæ¯
        cancel_msg = ToolMessage(
            content="ç”¨æˆ·å–æ¶ˆäº†å·¥å…·æ‰§è¡Œ",
            tool_call_id=tool_id,
            name=tool_name
        )
        st.session_state.messages.append(cancel_msg)
        st.session_state[executed_key] = True
        st.warning("âš ï¸ å·¥å…·è°ƒç”¨å·²å–æ¶ˆ")
        st.rerun()
    
    st.markdown('</div>', unsafe_allow_html=True)

def build_footer():
    """æ„å»ºé¡µé¢åº•éƒ¨ä¿¡æ¯"""
    st.divider()
    col1, col2, col3 = st.columns(3)
    with col1:
        conv_id = st.session_state.conversation_id
        conv_id_display = conv_id[:8] + "..." if conv_id else "æœªè®¾ç½®"
        st.caption(f"ğŸ†” å¯¹è¯ID: {conv_id_display}")
    with col2:
        st.caption(f"ğŸ’¬ æ¶ˆæ¯æ•°: {len(st.session_state.messages)}")
    with col3:
        st.caption("ğŸ§¬ RnAgent v2.1.0")

# è¿è¡Œä¸»ç¨‹åº
main()
