#!/usr/bin/env python3
"""
RNAåˆ†ææ™ºèƒ½ä½“æ ¸å¿ƒ - LangGraphå®ç°
è´Ÿè´£è‡ªç„¶è¯­è¨€å¤„ç†ã€å·¥å…·è°ƒç”¨å’Œå¯¹è¯ç®¡ç†
"""

import logging
import os
import asyncio
import json
import time
from typing import Dict, Any, List, Annotated, TypedDict, Literal
from datetime import datetime

# LangChainå’ŒLangGraphç›¸å…³å¯¼å…¥
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage, BaseMessage, SystemMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.graph import START, StateGraph
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode
from langgraph.types import Command
from pydantic import SecretStr

# MCP Adapters å¯¼å…¥
from langchain_mcp_adapters.client import MultiServerMCPClient

# è®¾ç½®è¯¦ç»†çš„æ—¥å¿—æ ¼å¼
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(name)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('rna_agent_graph.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# MCPæœåŠ¡å™¨é…ç½®
MCP_SERVER_URL = "http://localhost:8000/sse"

# å¼ºåŒ–çš„ç³»ç»Ÿæç¤º
SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„RNAå•ç»†èƒåˆ†ææ™ºèƒ½ä½“ã€‚

æ ¸å¿ƒè§„åˆ™ï¼š
1. å¯¹äºä»»ä½•éœ€è¦æ‰§è¡ŒPythonä»£ç çš„è¯·æ±‚ï¼Œä½ å¿…é¡»ä½¿ç”¨ mcp_Rnagent-MCP_python_repl_tool å·¥å…·
2. ä¸è¦ç›´æ¥ç»™å‡ºè®¡ç®—ç»“æœï¼Œè€Œæ˜¯å¿…é¡»é€šè¿‡å·¥å…·æ‰§è¡Œä»£ç æ¥è·å¾—ç»“æœ
3. å¦‚æœç”¨æˆ·è¦æ±‚è®¡ç®—ã€ç»˜å›¾ã€æ•°æ®åˆ†æç­‰ï¼Œéƒ½å¿…é¡»è°ƒç”¨ç›¸åº”çš„å·¥å…·
4. å³ä½¿æ˜¯ç®€å•çš„æ•°å­¦è®¡ç®—ï¼ˆå¦‚99*99ï¼‰ï¼Œä¹Ÿå¿…é¡»ä½¿ç”¨ python_repl_tool æ‰§è¡Œ print() è¯­å¥
5. å¯¹äºRNAåˆ†æç›¸å…³çš„ä»»åŠ¡ï¼Œä¼˜å…ˆä½¿ç”¨ä¸“é—¨çš„åˆ†æå·¥å…·ï¼ˆå¦‚load_pbmc3k_dataã€quality_control_analysisç­‰ï¼‰

å¯ç”¨å·¥å…·ï¼š
- mcp_Rnagent-MCP_python_repl_tool: æ‰§è¡ŒPythonä»£ç 
- mcp_Rnagent-MCP_load_pbmc3k_data: åŠ è½½PBMC3Kæ•°æ®
- mcp_Rnagent-MCP_quality_control_analysis: è´¨é‡æ§åˆ¶åˆ†æ
- mcp_Rnagent-MCP_preprocessing_analysis: æ•°æ®é¢„å¤„ç†
- mcp_Rnagent-MCP_dimensionality_reduction_analysis: é™ç»´åˆ†æ
- mcp_Rnagent-MCP_clustering_analysis: èšç±»åˆ†æ
- mcp_Rnagent-MCP_marker_genes_analysis: æ ‡è®°åŸºå› åˆ†æ
- mcp_Rnagent-MCP_generate_analysis_report: ç”Ÿæˆåˆ†ææŠ¥å‘Š
- mcp_Rnagent-MCP_complete_analysis_pipeline: å®Œæ•´åˆ†ææµç¨‹

è®°ä½ï¼šç»ä¸ç›´æ¥å›ç­”è®¡ç®—ç»“æœï¼Œå¿…é¡»é€šè¿‡å·¥å…·æ‰§è¡Œï¼"""


class AgentState(TypedDict):
    """æ™ºèƒ½ä½“çŠ¶æ€å®šä¹‰"""
    messages: Annotated[List[BaseMessage], add_messages]


class RNAAnalysisAgent:
    """RNAåˆ†ææ™ºèƒ½ä½“æ ¸å¿ƒç±»"""

    def __init__(self):
        logger.info("ğŸ§¬ [Agentåˆå§‹åŒ–] å¼€å§‹åˆå§‹åŒ–RNAåˆ†ææ™ºèƒ½ä½“")
        self.mcp_client = None
        self.tools = None
        self.graph = None
        # å¼‚æ­¥åˆå§‹åŒ–
        asyncio.run(self._async_init())
        logger.info("âœ… [Agentåˆå§‹åŒ–] RNAåˆ†ææ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ")

    async def _async_init(self):
        """å¼‚æ­¥åˆå§‹åŒ–MCPå®¢æˆ·ç«¯å’Œå·¥å…·"""
        logger.info("ğŸ”Œ [MCPåˆå§‹åŒ–] å¼€å§‹åˆå§‹åŒ–MCPå®¢æˆ·ç«¯")
        
        # åˆ›å»ºMCPå®¢æˆ·ç«¯
        self.mcp_client = MultiServerMCPClient({
            "rna_analysis": {
                "url": MCP_SERVER_URL,
                "transport": "sse",
            }
        })
        
        # è·å–å·¥å…·åˆ—è¡¨
        logger.info("ğŸ› ï¸ [å·¥å…·è·å–] ä»MCPæœåŠ¡å™¨åŠ¨æ€è·å–å·¥å…·åˆ—è¡¨")
        tools = await self.mcp_client.get_tools()
        
        # è®¾ç½® return_direct=True é¿å… LangGraph æ— é™å¾ªç¯
        for tool in tools:
            tool.return_direct = True
            
        self.tools = tools
        logger.info(f"âœ… [å·¥å…·åŠ è½½] æˆåŠŸåŠ è½½ {len(self.tools)} ä¸ªå·¥å…·: {[tool.name for tool in self.tools]}")
        
        # åˆ›å»ºå›¾
        self.graph = self._create_graph()

    def _create_graph(self):
        """åˆ›å»ºLangGraphå·¥ä½œæµ"""
        logger.info("ğŸ”§ [å›¾æ„å»º] å¼€å§‹åˆ›å»ºLangGraphå·¥ä½œæµ")

        # åˆ›å»ºçŠ¶æ€å›¾
        workflow = StateGraph(AgentState)

        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("llm", self._call_model)
        workflow.add_node("tools", ToolNode(self.tools))

        # è®¾ç½®è¾¹
        workflow.add_edge(START, "llm")
        workflow.add_conditional_edges(
            "llm",
            self._should_continue,
            {"continue": "tools", "end": "__end__"}
        )
        workflow.add_edge("tools", "llm")

        logger.info("âœ… [å›¾æ„å»º] LangGraphå·¥ä½œæµåˆ›å»ºå®Œæˆ")
        return workflow.compile()

    def _call_model(self, state: AgentState):
        """è°ƒç”¨è¯­è¨€æ¨¡å‹"""
        start_time = time.time()
        messages = state["messages"]

        logger.info("ğŸ§  [LLMè°ƒç”¨] å¼€å§‹è°ƒç”¨è¯­è¨€æ¨¡å‹")
        logger.info(f"ğŸ“¨ [è¾“å…¥æ¶ˆæ¯] æ¶ˆæ¯æ•°é‡: {len(messages)}")

        # ç¡®ä¿ç³»ç»Ÿæç¤ºå­˜åœ¨
        has_system_message = any(isinstance(msg, SystemMessage) for msg in messages)
        if not has_system_message:
            # åœ¨æ¶ˆæ¯åˆ—è¡¨å¼€å¤´æ’å…¥ç³»ç»Ÿæç¤º
            messages = [SystemMessage(content=SYSTEM_PROMPT)] + messages
            logger.info("ğŸ“‹ [ç³»ç»Ÿæç¤º] å·²æ·»åŠ å¼ºåŒ–çš„ç³»ç»Ÿæç¤º")

        # è®°å½•è¾“å…¥æ¶ˆæ¯è¯¦æƒ…
        for i, msg in enumerate(messages):
            msg_type = type(msg).__name__
            msg_content = getattr(msg, 'content', '')[:100] if hasattr(
                msg, 'content') else str(msg)[:100]
            logger.info(f"   [{i+1}] {msg_type}: {msg_content}...")

        # æ£€æŸ¥æ¶ˆæ¯æ•°é‡ï¼Œå¦‚æœè¶…è¿‡é˜ˆå€¼åˆ™è¿›è¡Œæˆªæ–­æˆ–æ‘˜è¦
        if len(messages) > 100:  # è®¾ç½®æœ€å¤§æ¶ˆæ¯æ•°é‡é˜ˆå€¼
            logger.info(f"ğŸ“ [æ¶ˆæ¯æˆªæ–­] æ¶ˆæ¯æ•°é‡ {len(messages)} è¶…è¿‡é˜ˆå€¼ï¼Œä¿ç•™æœ€è¿‘çš„50æ¡")
            # ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯å’Œæœ€è¿‘çš„49æ¡æ¶ˆæ¯
            system_msg = messages[0] if isinstance(messages[0], SystemMessage) else SystemMessage(content=SYSTEM_PROMPT)
            messages = [system_msg] + messages[-49:]
            # æ›´æ–°state
            state["messages"] = messages

        try:
            # è·å–LLMå®¢æˆ·ç«¯
            llm = self._get_llm_client()

            # ç»‘å®šå·¥å…·
            llm_with_tools = llm.bind_tools(self.tools)

            logger.info("ğŸš€ [LLMè°ƒç”¨] å‘é€è¯·æ±‚åˆ°è¯­è¨€æ¨¡å‹...")

            # è°ƒç”¨æ¨¡å‹
            response = llm_with_tools.invoke(messages)

            call_time = time.time() - start_time

            logger.info(f"âœ… [LLMå“åº”] æ¨¡å‹è°ƒç”¨å®Œæˆï¼Œè€—æ—¶: {call_time:.2f}s")
            logger.info(f"ğŸ“ [å“åº”å†…å®¹] {response.content[:200]}...")

            # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨ - ä¿®å¤æ–°ç‰ˆLangChainå…¼å®¹æ€§
            if isinstance(response, AIMessage) and hasattr(response, 'tool_calls') and response.tool_calls:
                logger.info(f"ğŸ”§ [å·¥å…·è°ƒç”¨] æ¨¡å‹è¯·æ±‚è°ƒç”¨ {len(response.tool_calls)} ä¸ªå·¥å…·:")
                for i, tool_call in enumerate(response.tool_calls):
                    logger.info(f"   [{i+1}] å·¥å…·: {tool_call['name']}")
                    logger.info(f"       å‚æ•°: {tool_call.get('args', {})}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰Python REPLå·¥å…·è°ƒç”¨ï¼Œå¦‚æœæœ‰åˆ™ç«‹å³æ·»åŠ å ä½ç¬¦ToolMessage
                messages_to_return = [response]
                has_python_repl = any(tool_call.get('name', '').endswith('python_repl_tool') 
                                    for tool_call in response.tool_calls)
                
                if has_python_repl:
                    logger.info("ğŸ“ [å ä½ç¬¦] æ£€æµ‹åˆ°Python REPLå·¥å…·è°ƒç”¨ï¼Œç«‹å³æ·»åŠ å ä½ç¬¦æ¶ˆæ¯")
                    for tool_call in response.tool_calls:
                        if tool_call.get('name', '').endswith('python_repl_tool'):
                            placeholder_tool_msg = ToolMessage(
                                content="[ç­‰å¾…ç”¨æˆ·ç¡®è®¤æ‰§è¡Œ]",
                                tool_call_id=tool_call.get('id', ''),
                                name=tool_call.get('name', '')
                            )
                            messages_to_return.append(placeholder_tool_msg)
                            logger.info(f"ğŸ“ [å ä½ç¬¦] ä¸ºå·¥å…· {tool_call.get('name', '')} æ·»åŠ å ä½ç¬¦æ¶ˆæ¯")
                
                return {"messages": messages_to_return}
            else:
                logger.info("âœ… [ç›´æ¥å“åº”] æ¨¡å‹ç”Ÿæˆäº†ç›´æ¥å›ç­”ï¼Œæ— éœ€è°ƒç”¨å·¥å…·")

            return {"messages": [response]}

        except Exception as e:
            call_time = time.time() - start_time
            logger.error(f"âŒ [LLMé”™è¯¯] æ¨¡å‹è°ƒç”¨å¤±è´¥ï¼Œè€—æ—¶: {call_time:.2f}s")
            logger.error(f"ğŸ”¥ [é”™è¯¯è¯¦æƒ…] {str(e)}")
            raise e

    def _should_force_tool_call(self, content: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥å¼ºåˆ¶è°ƒç”¨å·¥å…·"""
        if not content:
            return False
        
        content_lower = content.lower()
        force_indicators = [
            "è®¡ç®—", "æ‰§è¡Œ", "è¿è¡Œ", "print", "ä»£ç ", 
            "åˆ†æ", "ç»˜å›¾", "plot", "æ•°æ®", "ç»“æœ",
            "*", "+", "-", "/", "=", "99", "9999"
        ]
        
        return any(indicator in content_lower for indicator in force_indicators)

    def _should_continue(self, state: AgentState):
        """åˆ¤æ–­æ˜¯å¦ç»§ç»­æ‰§è¡Œå·¥å…·"""
        last_message = state["messages"][-1]

        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
        if isinstance(last_message, AIMessage) and hasattr(last_message, 'tool_calls') and last_message.tool_calls:
            # æ£€æŸ¥æ˜¯å¦æœ‰Python REPLå·¥å…·è°ƒç”¨ï¼Œå¦‚æœæœ‰åˆ™ä¸è‡ªåŠ¨æ‰§è¡Œï¼Œç­‰å¾…ç”¨æˆ·ç¡®è®¤
            has_python_repl = any(tool_call.get('name', '').endswith('python_repl_tool') 
                                for tool_call in last_message.tool_calls)
            
            if has_python_repl:
                logger.info("â¸ï¸ [æµç¨‹åˆ¤æ–­] æ£€æµ‹åˆ°Python REPLå·¥å…·è°ƒç”¨ï¼Œæ·»åŠ å ä½ç¬¦å·¥å…·æ¶ˆæ¯ä»¥ä¿æŒåºåˆ—å®Œæ•´æ€§")
                
                # ä¸ºæ¯ä¸ªPython REPLå·¥å…·è°ƒç”¨æ·»åŠ å ä½ç¬¦ToolMessageï¼Œä»¥ä¿æŒæ¶ˆæ¯åºåˆ—çš„å®Œæ•´æ€§
                for tool_call in last_message.tool_calls:
                    if tool_call.get('name', '').endswith('python_repl_tool'):
                        placeholder_tool_msg = ToolMessage(
                            content="[ç­‰å¾…ç”¨æˆ·ç¡®è®¤æ‰§è¡Œ]",
                            tool_call_id=tool_call.get('id', ''),
                            name=tool_call.get('name', '')
                        )
                        state["messages"].append(placeholder_tool_msg)
                        logger.info(f"ğŸ“ [å ä½ç¬¦] ä¸ºå·¥å…· {tool_call.get('name', '')} æ·»åŠ å ä½ç¬¦æ¶ˆæ¯")
                
                return "end"
            else:
                logger.info("ğŸ”„ [æµç¨‹åˆ¤æ–­] éœ€è¦æ‰§è¡Œå…¶ä»–å·¥å…·ï¼Œç»§ç»­åˆ°å·¥å…·èŠ‚ç‚¹")
                return "continue"
        else:
            logger.info("ğŸ [æµç¨‹åˆ¤æ–­] æ— éœ€æ‰§è¡Œå·¥å…·ï¼Œæµç¨‹ç»“æŸ")
            return "end"

    def _get_llm_client(self):
        """è·å–LLMå®¢æˆ·ç«¯"""
        # ä¼˜å…ˆä½¿ç”¨OpenAI APIï¼ˆæ›´ç¨³å®šï¼‰
        openai_key = os.environ.get("OPENAI_API_KEY")
        if openai_key and openai_key != "your_openai_api_key_here":
            logger.info("ğŸ”‘ [LLMé…ç½®] ä½¿ç”¨OpenAI API")
            return ChatOpenAI(
                model="gpt-4o",  # ä½¿ç”¨å®Œæ•´ç‰ˆgpt-4oï¼Œfunction callingæ›´ç¨³å®š
                temperature=0,
                api_key=SecretStr(openai_key)
            )
        # å¤‡ç”¨DeepSeek API
        deepseek_key = os.environ.get("DEEPSEEK_API_KEY")
        deepseek_base_url = os.environ.get("DEEPSEEK_BASE_URL", "https://api.deepseek.com/v1")
        if deepseek_key and deepseek_key != "your_deepseek_api_key_here":
            logger.info(f"ğŸ”‘ [LLMé…ç½®] ä½¿ç”¨DeepSeek API, Base URL: {deepseek_base_url}")
            return ChatOpenAI(
                model="deepseek-chat",
                temperature=0,  # è®¾ç½®ä¸º0æé«˜ç¡®å®šæ€§
                api_key=SecretStr(deepseek_key),
                base_url=deepseek_base_url
            )
        else:
            logger.error("âŒ [LLMé…ç½®] æœªæ‰¾åˆ°æœ‰æ•ˆçš„APIå¯†é’¥")
            logger.error("   è¯·åœ¨env.templateä¸­è®¾ç½®çœŸå®çš„APIå¯†é’¥")
            raise ValueError(
                "No valid API key found. Please set a real OPENAI_API_KEY or DEEPSEEK_API_KEY in env.template")

    async def process_message_async(self, message: str, history: List[BaseMessage] = None) -> Dict[str, Any]:
        """å¼‚æ­¥å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼Œæ”¯æŒå†å²æ¶ˆæ¯"""
        start_time = time.time()

        try:
            logger.info("ğŸ¯ [æ¶ˆæ¯å¤„ç†] å¼€å§‹å¤„ç†ç”¨æˆ·æ¶ˆæ¯")
            logger.info(f"ğŸ“ [è¾“å…¥æ¶ˆæ¯] {message}")
            
            # å‡†å¤‡æ¶ˆæ¯åˆ—è¡¨
            messages = []
            
            # æ·»åŠ å†å²æ¶ˆæ¯
            if history:
                messages.extend(history)
                logger.info(f"ğŸ“š [å†å²åŠ è½½] åŠ è½½äº† {len(history)} æ¡å†å²æ¶ˆæ¯")
            
            # æ·»åŠ æ–°çš„ç”¨æˆ·æ¶ˆæ¯
            messages.append(HumanMessage(content=message))

            # åˆ›å»ºè¾“å…¥çŠ¶æ€
            initial_state = {
                "messages": messages
            }

            logger.info("ğŸš€ [å›¾æ‰§è¡Œ] å¼€å§‹æ‰§è¡ŒLangGraphå·¥ä½œæµ")
            logger.info(f"ğŸ“Š [åˆå§‹çŠ¶æ€] æ€»æ¶ˆæ¯æ•°: {len(messages)}")

            # è¿è¡Œå›¾ - ä½¿ç”¨å¼‚æ­¥è°ƒç”¨ï¼Œè®¾ç½®é€’å½’é™åˆ¶
            config = {"recursion_limit": 15}
            result = await self.graph.ainvoke(initial_state, config=config)

            process_time = time.time() - start_time

            # è·å–æœ€ç»ˆæ¶ˆæ¯
            final_messages = result.get("messages", [])
            final_response = ""

            # æŸ¥æ‰¾æœ€åä¸€æ¡AIæ¶ˆæ¯ä½œä¸ºæœ€ç»ˆå“åº”
            for msg in reversed(final_messages):
                if isinstance(msg, AIMessage):
                    final_response = msg.content
                    break

            if not final_response:
                final_response = "æŠ±æ­‰ï¼Œå¤„ç†å®Œæˆä½†æ²¡æœ‰ç”Ÿæˆå“åº”ã€‚"

            logger.info(f"âœ… [å¤„ç†å®Œæˆ] æ¶ˆæ¯å¤„ç†æˆåŠŸï¼Œè€—æ—¶: {process_time:.2f}s")
            logger.info(f"ğŸ“Š [æœ€ç»ˆçŠ¶æ€] æ€»æ¶ˆæ¯æ•°: {len(final_messages)}")
            logger.info(f"ğŸ“¤ [æœ€ç»ˆå“åº”] {final_response[:200]}...")

            return {
                "success": True,
                "final_response": final_response,
                "messages": final_messages,
                "process_time": process_time
            }

        except Exception as e:
            process_time = time.time() - start_time
            logger.error(f"âŒ [å¤„ç†é”™è¯¯] æ¶ˆæ¯å¤„ç†å¤±è´¥ï¼Œè€—æ—¶: {process_time:.2f}s")
            logger.error(f"ğŸ”¥ [é”™è¯¯è¯¦æƒ…] {str(e)}")

            import traceback
            logger.error(f"ğŸ“‹ [é”™è¯¯æ ˆ] {traceback.format_exc()}")

            return {
                "success": False,
                "error": f"å¤„ç†æ¶ˆæ¯æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}",
                "messages": [],
                "process_time": process_time
            }

    def process_message(self, message: str, history: List[BaseMessage] = None) -> Dict[str, Any]:
        """åŒæ­¥åŒ…è£…çš„æ¶ˆæ¯å¤„ç†å‡½æ•°"""
        # æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨äº‹ä»¶å¾ªç¯ä¸­
        try:
            loop = asyncio.get_running_loop()
            # å¦‚æœå·²ç»åœ¨äº‹ä»¶å¾ªç¯ä¸­ï¼Œåˆ›å»ºæ–°ä»»åŠ¡
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(asyncio.run, self.process_message_async(message, history))
                return future.result()
        except RuntimeError:
            # æ²¡æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨asyncio.run
            return asyncio.run(self.process_message_async(message, history))


# åˆ›å»ºå…¨å±€æ™ºèƒ½ä½“å®ä¾‹
logger.info("ğŸ—ï¸ [ç³»ç»Ÿåˆå§‹åŒ–] åˆ›å»ºå…¨å±€RNAæ™ºèƒ½ä½“å®ä¾‹")
rna_agent = RNAAnalysisAgent()


def process_user_message(message: str) -> Dict[str, Any]:
    """å¤„ç†ç”¨æˆ·æ¶ˆæ¯çš„ä¸»å…¥å£å‡½æ•°"""
    logger.info(f"ğŸ“¨ [å…¥å£å‡½æ•°] æ”¶åˆ°ç”¨æˆ·æ¶ˆæ¯: {message}")
    result = rna_agent.process_message(message)
    logger.info(f"ğŸ“¤ [å…¥å£å‡½æ•°] è¿”å›å¤„ç†ç»“æœ: success={result['success']}")
    return result

def process_user_message_with_history(message: str, history: List[BaseMessage] = None) -> Dict[str, Any]:
    """å¤„ç†ç”¨æˆ·æ¶ˆæ¯çš„ä¸»å…¥å£å‡½æ•°ï¼Œæ”¯æŒå†å²è®°å¿†"""
    logger.info(f"ğŸ“¨ [å…¥å£å‡½æ•°] æ”¶åˆ°ç”¨æˆ·æ¶ˆæ¯: {message}")
    logger.info(f"ğŸ“š [å…¥å£å‡½æ•°] å†å²æ¶ˆæ¯æ•°é‡: {len(history) if history else 0}")
    
    result = rna_agent.process_message(message, history)
    logger.info(f"ğŸ“¤ [å…¥å£å‡½æ•°] è¿”å›å¤„ç†ç»“æœ: success={result['success']}")
    logger.info(f"ğŸ’¬ [å…¥å£å‡½æ•°] æœ€ç»ˆæ¶ˆæ¯æ•°é‡: {len(result.get('messages', []))}")
    
    return result


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("ğŸ§¬ RNAåˆ†ææ™ºèƒ½ä½“æ ¸å¿ƒå¯åŠ¨")

    # æµ‹è¯•æ¶ˆæ¯å¤„ç†
    test_message = "è¯·è®¡ç®—99*99"
    result = process_user_message(test_message)

    if result["success"]:
        print("âœ… æ™ºèƒ½ä½“å¤„ç†æˆåŠŸ")
        print(f"å“åº”: {result['final_response']}")
    else:
        print(f"âŒ å¤„ç†å¤±è´¥: {result['error']}")
